{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "t_D.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "bD8-8ws4wsKT",
        "colab_type": "code",
        "outputId": "7d07180a-d9f9-4e79-f2c0-160256bb22ec",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "cd /content"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ICPZ55sBYzue",
        "colab_type": "code",
        "outputId": "f27ef38e-7b58-45af-fc68-06aa3f894bc6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 323
        }
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Thu Aug  8 08:33:30 2019       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 418.67       Driver Version: 410.79       CUDA Version: 10.0     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   37C    P8    15W /  70W |      0MiB / 15079MiB |      0%      Default |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                       GPU Memory |\n",
            "|  GPU       PID   Type   Process name                             Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "uPGhX_Qy8ZSg",
        "outputId": "832b1373-3e93-4e3c-9b07-98b3f97d6eca",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 127
        }
      },
      "source": [
        "! pip install sentencepiece"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting sentencepiece\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/00/95/7f357995d5eb1131aa2092096dca14a6fc1b1d2860bd99c22a612e1d1019/sentencepiece-0.1.82-cp36-cp36m-manylinux1_x86_64.whl (1.0MB)\n",
            "\u001b[K     |████████████████████████████████| 1.0MB 6.4MB/s \n",
            "\u001b[?25hInstalling collected packages: sentencepiece\n",
            "Successfully installed sentencepiece-0.1.82\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b_GfWUSGyci2",
        "colab_type": "code",
        "outputId": "01044775-972d-4658-d7d3-4fd41278935b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 161
        }
      },
      "source": [
        "! rm -rf xlnet_train\n",
        "! git clone https://github.com/Stodgers/xlnet_train.git\n",
        "! pip install sentencepiece"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'xlnet_train'...\n",
            "remote: Enumerating objects: 174, done.\u001b[K\n",
            "remote: Counting objects:   0% (1/174)\u001b[K\rremote: Counting objects:   1% (2/174)\u001b[K\rremote: Counting objects:   2% (4/174)\u001b[K\rremote: Counting objects:   3% (6/174)\u001b[K\rremote: Counting objects:   4% (7/174)\u001b[K\rremote: Counting objects:   5% (9/174)\u001b[K\rremote: Counting objects:   6% (11/174)\u001b[K\rremote: Counting objects:   7% (13/174)\u001b[K\rremote: Counting objects:   8% (14/174)\u001b[K\rremote: Counting objects:   9% (16/174)\u001b[K\rremote: Counting objects:  10% (18/174)\u001b[K\rremote: Counting objects:  11% (20/174)\u001b[K\rremote: Counting objects:  12% (21/174)\u001b[K\rremote: Counting objects:  13% (23/174)\u001b[K\rremote: Counting objects:  14% (25/174)\u001b[K\rremote: Counting objects:  15% (27/174)\u001b[K\rremote: Counting objects:  16% (28/174)\u001b[K\rremote: Counting objects:  17% (30/174)\u001b[K\rremote: Counting objects:  18% (32/174)\u001b[K\rremote: Counting objects:  19% (34/174)\u001b[K\rremote: Counting objects:  20% (35/174)\u001b[K\rremote: Counting objects:  21% (37/174)\u001b[K\rremote: Counting objects:  22% (39/174)\u001b[K\rremote: Counting objects:  23% (41/174)\u001b[K\rremote: Counting objects:  24% (42/174)\u001b[K\rremote: Counting objects:  25% (44/174)\u001b[K\rremote: Counting objects:  26% (46/174)\u001b[K\rremote: Counting objects:  27% (47/174)\u001b[K\rremote: Counting objects:  28% (49/174)\u001b[K\rremote: Counting objects:  29% (51/174)\u001b[K\rremote: Counting objects:  30% (53/174)\u001b[K\rremote: Counting objects:  31% (54/174)\u001b[K\rremote: Counting objects:  32% (56/174)\u001b[K\rremote: Counting objects:  33% (58/174)\u001b[K\rremote: Counting objects:  34% (60/174)\u001b[K\rremote: Counting objects:  35% (61/174)\u001b[K\rremote: Counting objects:  36% (63/174)\u001b[K\rremote: Counting objects:  37% (65/174)\u001b[K\rremote: Counting objects:  38% (67/174)\u001b[K\rremote: Counting objects:  39% (68/174)\u001b[K\rremote: Counting objects:  40% (70/174)\u001b[K\rremote: Counting objects:  41% (72/174)\u001b[K\rremote: Counting objects:  42% (74/174)\u001b[K\rremote: Counting objects:  43% (75/174)\u001b[K\rremote: Counting objects:  44% (77/174)\u001b[K\rremote: Counting objects:  45% (79/174)\u001b[K\rremote: Counting objects:  46% (81/174)\u001b[K\rremote: Counting objects:  47% (82/174)\u001b[K\rremote: Counting objects:  48% (84/174)\u001b[K\rremote: Counting objects:  49% (86/174)\u001b[K\rremote: Counting objects:  50% (87/174)\u001b[K\rremote: Counting objects:  51% (89/174)\u001b[K\rremote: Counting objects:  52% (91/174)\u001b[K\rremote: Counting objects:  53% (93/174)\u001b[K\rremote: Counting objects:  54% (94/174)\u001b[K\rremote: Counting objects:  55% (96/174)\u001b[K\rremote: Counting objects:  56% (98/174)\u001b[K\rremote: Counting objects:  57% (100/174)\u001b[K\rremote: Counting objects:  58% (101/174)\u001b[K\rremote: Counting objects:  59% (103/174)\u001b[K\rremote: Counting objects:  60% (105/174)\u001b[K\rremote: Counting objects:  61% (107/174)\u001b[K\rremote: Counting objects:  62% (108/174)\u001b[K\rremote: Counting objects:  63% (110/174)\u001b[K\rremote: Counting objects:  64% (112/174)\u001b[K\rremote: Counting objects:  65% (114/174)\u001b[K\rremote: Counting objects:  66% (115/174)\u001b[K\rremote: Counting objects:  67% (117/174)\u001b[K\rremote: Counting objects:  68% (119/174)\u001b[K\rremote: Counting objects:  69% (121/174)\u001b[K\rremote: Counting objects:  70% (122/174)\u001b[K\rremote: Counting objects:  71% (124/174)\u001b[K\rremote: Counting objects:  72% (126/174)\u001b[K\rremote: Counting objects:  73% (128/174)\u001b[K\rremote: Counting objects:  74% (129/174)\u001b[K\rremote: Counting objects:  75% (131/174)\u001b[K\rremote: Counting objects:  76% (133/174)\u001b[K\rremote: Counting objects:  77% (134/174)\u001b[K\rremote: Counting objects:  78% (136/174)\u001b[K\rremote: Counting objects:  79% (138/174)\u001b[K\rremote: Counting objects:  80% (140/174)\u001b[K\rremote: Counting objects:  81% (141/174)\u001b[K\rremote: Counting objects:  82% (143/174)\u001b[K\rremote: Counting objects:  83% (145/174)\u001b[K\rremote: Counting objects:  84% (147/174)\u001b[K\rremote: Counting objects:  85% (148/174)\u001b[K\rremote: Counting objects:  86% (150/174)\u001b[K\rremote: Counting objects:  87% (152/174)\u001b[K\rremote: Counting objects:  88% (154/174)\u001b[K\rremote: Counting objects:  89% (155/174)\u001b[K\rremote: Counting objects:  90% (157/174)\u001b[K\rremote: Counting objects:  91% (159/174)\u001b[K\rremote: Counting objects:  92% (161/174)\u001b[K\rremote: Counting objects:  93% (162/174)\u001b[K\rremote: Counting objects:  94% (164/174)\u001b[K\rremote: Counting objects:  95% (166/174)\u001b[K\rremote: Counting objects:  96% (168/174)\u001b[K\rremote: Counting objects:  97% (169/174)\u001b[K\rremote: Counting objects:  98% (171/174)\u001b[K\rremote: Counting objects:  99% (173/174)\u001b[K\rremote: Counting objects: 100% (174/174)\u001b[K\rremote: Counting objects: 100% (174/174), done.\u001b[K\n",
            "remote: Compressing objects:   0% (1/120)\u001b[K\rremote: Compressing objects:   1% (2/120)\u001b[K\rremote: Compressing objects:   2% (3/120)\u001b[K\rremote: Compressing objects:   3% (4/120)\u001b[K\rremote: Compressing objects:   4% (5/120)\u001b[K\rremote: Compressing objects:   5% (6/120)\u001b[K\rremote: Compressing objects:   6% (8/120)\u001b[K\rremote: Compressing objects:   7% (9/120)\u001b[K\rremote: Compressing objects:   8% (10/120)\u001b[K\rremote: Compressing objects:   9% (11/120)\u001b[K\rremote: Compressing objects:  10% (12/120)\u001b[K\rremote: Compressing objects:  11% (14/120)\u001b[K\rremote: Compressing objects:  12% (15/120)\u001b[K\rremote: Compressing objects:  13% (16/120)\u001b[K\rremote: Compressing objects:  14% (17/120)\u001b[K\rremote: Compressing objects:  15% (18/120)\u001b[K\rremote: Compressing objects:  16% (20/120)\u001b[K\rremote: Compressing objects:  17% (21/120)\u001b[K\rremote: Compressing objects:  18% (22/120)\u001b[K\rremote: Compressing objects:  19% (23/120)\u001b[K\rremote: Compressing objects:  20% (24/120)\u001b[K\rremote: Compressing objects:  21% (26/120)\u001b[K\rremote: Compressing objects:  22% (27/120)\u001b[K\rremote: Compressing objects:  23% (28/120)\u001b[K\rremote: Compressing objects:  24% (29/120)\u001b[K\rremote: Compressing objects:  25% (30/120)\u001b[K\rremote: Compressing objects:  26% (32/120)\u001b[K\rremote: Compressing objects:  27% (33/120)\u001b[K\rremote: Compressing objects:  28% (34/120)\u001b[K\rremote: Compressing objects:  29% (35/120)\u001b[K\rremote: Compressing objects:  30% (36/120)\u001b[K\rremote: Compressing objects:  31% (38/120)\u001b[K\rremote: Compressing objects:  32% (39/120)\u001b[K\rremote: Compressing objects:  33% (40/120)\u001b[K\rremote: Compressing objects:  34% (41/120)\u001b[K\rremote: Compressing objects:  35% (42/120)\u001b[K\rremote: Compressing objects:  36% (44/120)\u001b[K\rremote: Compressing objects:  37% (45/120)\u001b[K\rremote: Compressing objects:  38% (46/120)\u001b[K\rremote: Compressing objects:  39% (47/120)\u001b[K\rremote: Compressing objects:  40% (48/120)\u001b[K\rremote: Compressing objects:  41% (50/120)\u001b[K\rremote: Compressing objects:  42% (51/120)\u001b[K\rremote: Compressing objects:  43% (52/120)\u001b[K\rremote: Compressing objects:  44% (53/120)\u001b[K\rremote: Compressing objects:  45% (54/120)\u001b[K\rremote: Compressing objects:  46% (56/120)\u001b[K\rremote: Compressing objects:  47% (57/120)\u001b[K\rremote: Compressing objects:  48% (58/120)\u001b[K\rremote: Compressing objects:  49% (59/120)\u001b[K\rremote: Compressing objects:  50% (60/120)\u001b[K\rremote: Compressing objects:  51% (62/120)\u001b[K\rremote: Compressing objects:  52% (63/120)\u001b[K\rremote: Compressing objects:  53% (64/120)\u001b[K\rremote: Compressing objects:  54% (65/120)\u001b[K\rremote: Compressing objects:  55% (66/120)\u001b[K\rremote: Compressing objects:  56% (68/120)\u001b[K\rremote: Compressing objects:  57% (69/120)\u001b[K\rremote: Compressing objects:  58% (70/120)\u001b[K\rremote: Compressing objects:  59% (71/120)\u001b[K\rremote: Compressing objects:  60% (72/120)\u001b[K\rremote: Compressing objects:  61% (74/120)\u001b[K\rremote: Compressing objects:  62% (75/120)\u001b[K\rremote: Compressing objects:  63% (76/120)\u001b[K\rremote: Compressing objects:  64% (77/120)\u001b[K\rremote: Compressing objects:  65% (78/120)\u001b[K\rremote: Compressing objects:  66% (80/120)\u001b[K\rremote: Compressing objects:  67% (81/120)\u001b[K\rremote: Compressing objects:  68% (82/120)\u001b[K\rremote: Compressing objects:  69% (83/120)\u001b[K\rremote: Compressing objects:  70% (84/120)\u001b[K\rremote: Compressing objects:  71% (86/120)\u001b[K\rremote: Compressing objects:  72% (87/120)\u001b[K\rremote: Compressing objects:  73% (88/120)\u001b[K\rremote: Compressing objects:  74% (89/120)\u001b[K\rremote: Compressing objects:  75% (90/120)\u001b[K\rremote: Compressing objects:  76% (92/120)\u001b[K\rremote: Compressing objects:  77% (93/120)\u001b[K\rremote: Compressing objects:  78% (94/120)\u001b[K\rremote: Compressing objects:  79% (95/120)\u001b[K\rremote: Compressing objects:  80% (96/120)\u001b[K\rremote: Compressing objects:  81% (98/120)\u001b[K\rremote: Compressing objects:  82% (99/120)\u001b[K\rremote: Compressing objects:  83% (100/120)\u001b[K\rremote: Compressing objects:  84% (101/120)\u001b[K\rremote: Compressing objects:  85% (102/120)\u001b[K\rremote: Compressing objects:  86% (104/120)\u001b[K\rremote: Compressing objects:  87% (105/120)\u001b[K\rremote: Compressing objects:  88% (106/120)\u001b[K\rremote: Compressing objects:  89% (107/120)\u001b[K\rremote: Compressing objects:  90% (108/120)\u001b[K\rremote: Compressing objects:  91% (110/120)\u001b[K\rremote: Compressing objects:  92% (111/120)\u001b[K\rremote: Compressing objects:  93% (112/120)\u001b[K\rremote: Compressing objects:  94% (113/120)\u001b[K\rremote: Compressing objects:  95% (114/120)\u001b[K\rremote: Compressing objects:  96% (116/120)\u001b[K\rremote: Compressing objects:  97% (117/120)\u001b[K\rremote: Compressing objects:  98% (118/120)\u001b[K\rremote: Compressing objects:  99% (119/120)\u001b[K\rremote: Compressing objects: 100% (120/120)\u001b[K\rremote: Compressing objects: 100% (120/120), done.\u001b[K\n",
            "Receiving objects:   0% (1/174)   \rReceiving objects:   1% (2/174)   \rReceiving objects:   2% (4/174)   \rReceiving objects:   3% (6/174)   \rReceiving objects:   4% (7/174)   \rReceiving objects:   5% (9/174)   \rReceiving objects:   6% (11/174)   \rReceiving objects:   7% (13/174)   \rReceiving objects:   8% (14/174)   \rReceiving objects:   9% (16/174)   \rReceiving objects:  10% (18/174)   \rReceiving objects:  11% (20/174)   \rReceiving objects:  12% (21/174)   \rReceiving objects:  13% (23/174)   \rReceiving objects:  14% (25/174)   \rReceiving objects:  15% (27/174)   \rReceiving objects:  16% (28/174)   \rReceiving objects:  17% (30/174)   \rReceiving objects:  18% (32/174)   \rReceiving objects:  19% (34/174)   \rReceiving objects:  20% (35/174)   \rReceiving objects:  21% (37/174)   \rReceiving objects:  22% (39/174)   \rReceiving objects:  23% (41/174)   \rReceiving objects:  24% (42/174)   \rReceiving objects:  25% (44/174)   \rReceiving objects:  26% (46/174)   \rReceiving objects:  27% (47/174)   \rReceiving objects:  28% (49/174)   \rReceiving objects:  29% (51/174)   \rReceiving objects:  30% (53/174)   \rReceiving objects:  31% (54/174)   \rReceiving objects:  32% (56/174)   \rReceiving objects:  33% (58/174)   \rReceiving objects:  34% (60/174)   \rReceiving objects:  35% (61/174)   \rReceiving objects:  36% (63/174)   \rReceiving objects:  37% (65/174)   \rReceiving objects:  38% (67/174)   \rReceiving objects:  39% (68/174)   \rReceiving objects:  40% (70/174)   \rReceiving objects:  41% (72/174)   \rReceiving objects:  42% (74/174)   \rReceiving objects:  43% (75/174)   \rremote: Total 174 (delta 57), reused 151 (delta 36), pack-reused 0\u001b[K\n",
            "Receiving objects:  44% (77/174)   \rReceiving objects:  45% (79/174)   \rReceiving objects:  46% (81/174)   \rReceiving objects:  47% (82/174)   \rReceiving objects:  48% (84/174)   \rReceiving objects:  49% (86/174)   \rReceiving objects:  50% (87/174)   \rReceiving objects:  51% (89/174)   \rReceiving objects:  52% (91/174)   \rReceiving objects:  53% (93/174)   \rReceiving objects:  54% (94/174)   \rReceiving objects:  55% (96/174)   \rReceiving objects:  56% (98/174)   \rReceiving objects:  57% (100/174)   \rReceiving objects:  58% (101/174)   \rReceiving objects:  59% (103/174)   \rReceiving objects:  60% (105/174)   \rReceiving objects:  61% (107/174)   \rReceiving objects:  62% (108/174)   \rReceiving objects:  63% (110/174)   \rReceiving objects:  64% (112/174)   \rReceiving objects:  65% (114/174)   \rReceiving objects:  66% (115/174)   \rReceiving objects:  67% (117/174)   \rReceiving objects:  68% (119/174)   \rReceiving objects:  69% (121/174)   \rReceiving objects:  70% (122/174)   \rReceiving objects:  71% (124/174)   \rReceiving objects:  72% (126/174)   \rReceiving objects:  73% (128/174)   \rReceiving objects:  74% (129/174)   \rReceiving objects:  75% (131/174)   \rReceiving objects:  76% (133/174)   \rReceiving objects:  77% (134/174)   \rReceiving objects:  78% (136/174)   \rReceiving objects:  79% (138/174)   \rReceiving objects:  80% (140/174)   \rReceiving objects:  81% (141/174)   \rReceiving objects:  82% (143/174)   \rReceiving objects:  83% (145/174)   \rReceiving objects:  84% (147/174)   \rReceiving objects:  85% (148/174)   \rReceiving objects:  86% (150/174)   \rReceiving objects:  87% (152/174)   \rReceiving objects:  88% (154/174)   \rReceiving objects:  89% (155/174)   \rReceiving objects:  90% (157/174)   \rReceiving objects:  91% (159/174)   \rReceiving objects:  92% (161/174)   \rReceiving objects:  93% (162/174)   \rReceiving objects:  94% (164/174)   \rReceiving objects:  95% (166/174)   \rReceiving objects:  96% (168/174)   \rReceiving objects:  97% (169/174)   \rReceiving objects:  98% (171/174)   \rReceiving objects:  99% (173/174)   \rReceiving objects: 100% (174/174)   \rReceiving objects: 100% (174/174), 1.87 MiB | 21.00 MiB/s, done.\n",
            "Resolving deltas:   0% (0/57)   \rResolving deltas:   5% (3/57)   \rResolving deltas:   8% (5/57)   \rResolving deltas:  43% (25/57)   \rResolving deltas:  50% (29/57)   \rResolving deltas:  54% (31/57)   \rResolving deltas:  59% (34/57)   \rResolving deltas:  63% (36/57)   \rResolving deltas:  66% (38/57)   \rResolving deltas:  68% (39/57)   \rResolving deltas:  80% (46/57)   \rResolving deltas:  85% (49/57)   \rResolving deltas:  87% (50/57)   \rResolving deltas:  92% (53/57)   \rResolving deltas:  98% (56/57)   \rResolving deltas: 100% (57/57)   \rResolving deltas: 100% (57/57), done.\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.6/dist-packages (0.1.82)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gKrbHMq60lzO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cp /content/drive/T-news_sohusite_xml.txt /content/xlnet_train/data/sogou_news"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0UGoYhjqygUA",
        "colab_type": "code",
        "outputId": "762f3878-ba52-402e-d044-bace4bcae1ff",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "cd /content/xlnet_train/data/sogou_news"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/xlnet_train/data/sogou_news\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qyQDrJ2D4Lyl",
        "colab_type": "code",
        "outputId": "5363a777-7482-482a-cba7-b3d50d861d53",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "#! python sogou_data_utils.py"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "T-news_sohusite_xml.smarty.txt\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-zS-UxkNQTZ7",
        "colab_type": "code",
        "outputId": "684dae7d-36fa-4a77-80c2-b65501d73cc0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "cd /content/xlnet_train/data/sogou_news"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/xlnet_train/data/sogou_news\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1y3mrEcgZkv1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "path = \"T-news_sohusite_xml.txt\"\n",
        "with open(\"T-news_sohusite_xml_xml.txt\",'a',encoding='utf-8',errors='ignore') as f:\n",
        "  data = open(path,encoding='utf-8',errors='ignore')\n",
        "  k=0\n",
        "  for i in data.readlines():\n",
        "    if k>=1000000:break\n",
        "    k+=1\n",
        "    f.write(i)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2co9TyulbZ7N",
        "colab_type": "code",
        "outputId": "0294354a-38d2-44a5-b40d-3b500e3335ce",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 217
        }
      },
      "source": [
        "!head /content/xlnet_train/data/sogou_news/T-news_sohusite_xml_xml.txt"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "深圳地铁将设立ＶＩＰ头等车厢买双倍票可享坐票\n",
            "南都讯记者刘凡周昌和任笑一继推出日票后，深圳今后将设地铁ＶＩＰ头等车厢，设坐票制。昨日，《南都ＭＥＴＲＯ》创刊仪式暨２０１２年深港地铁圈高峰论坛上透露，在未来的１１号线上将增加特色服务，满足不同消费层次的乘客的不同需求，如特设行李架的车厢和买双倍票可有座位坐的ＶＩＰ车厢等。论坛上，深圳市政府副秘书长、轨道交通建设办公室主任赵鹏林透露，地铁未来的方向将分等级，满足不同层次的人的需求，提供不同层次的有针对的服务。其中包括一些档次稍微高一些的服务。“我们要让公共交通也能满足档次稍高一些的服务”。比如，尝试有座位的地铁票服务。尤其是一些远道而来的乘客，通过提供坐票服务，让乘坐地铁也能享受到非常舒适的体验。他说，这种坐票的服务有望在地铁３期上实行，将加挂２节车厢以实施花钱可买座位的服务。“我们希望轨道交通和家里开的车一样，分很多种。”赵鹏林说，比如有些地铁是“观光线”，不仅沿途的风光非常好，还能凭一张票无数次上下，如同旅游时提供的“通票服务”。再比如，设立可以放大件行李的车厢，今后通过设专门可放大件行李的座位，避免像现在放行李不太方便的现象。“未来地铁初步不仅在干线上铺设，还会在支线、城际线上去建设。”“觉得如果车费不太贵的话，还是愿意考虑的。”昨日市民黄小姐表示，尤其是从老街到机场这一段，老街站每次上下客都很多人，而如果赶上上下班高峰期，特别拥挤，要一路从老街站站到机场，４０、５０分钟还是挺吃力的，宁愿多花点钱也能稍微舒适一点。但是白领林先生则表示，自己每天上下班都要坐地铁，出双倍车资买坐票费用有点高。\n",
            "\n",
            "中国西部是地球上主要干旱带之一，妇女是当地劳动力．．．\n",
            "同心县地处宁夏中部干旱带的核心区，冬寒长，春暖迟，夏热短，秋凉早，干旱少雨，蒸发强烈，风大沙多。主要自然灾害有沙尘暴、干热风、霜冻、冰雹等，其中以干旱危害最为严重。由于生态环境的极度恶劣，导致农村经济发展缓慢，人民群众生产、生活水平低下，靠天吃饭的被动局面依然存在，同心，又是国家级老、少、边、穷县之一…［详细］\n",
            "\n",
            "思源焦点公益基金救助孩子：永康\n",
            "不满一岁的永康是个饱经病痛折磨的孩子，２０１１年７月５日出生的他，患有先天性心脏病、疝气，一出生便被遗弃。２０１２年１月８日，才５个月大的永康被发现呼吸困难，随后送往医院进行抢救治疗，病情稳定后于１月２８日出院。２０１２年２月１３号，永康在思源焦点公益基金的帮助下在医院接受手术治疗，术后仅８天，永康突发右侧腹股沟斜疝嵌顿及肠梗阻，又再次进行抢救治疗，术后进重症监护室。３月７日，几经病痛折磨的永康终于康复出院，目前他的病情已经稳定。\n",
            "\n",
            "康师傅回应转卖废弃茶叶：下家承诺用废料做枕头\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6SjlqgWv5Qt4",
        "colab_type": "code",
        "outputId": "4f25a2d5-488b-41fd-f113-898b38fa3ca2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "import sentencepiece as spm\n",
        "RAW_DATA_FPATH = \"T-news_sohusite_xml_xml.txt\"\n",
        "\n",
        "MODEL_PREFIX = \"sp10m.cased.v3\"\n",
        "VOC_SIZE = 9000\n",
        "COVERAGE = 1.0\n",
        "SPM_COMMAND = ('--input={} '\n",
        "               '--model_prefix={} '\n",
        "               '--vocab_size={} '\n",
        "               '--character_coverage={} '\n",
        "               '--shuffle_input_sentence=true ' \n",
        "               '--model_type=bpe '\n",
        "               '--control_symbols=<cls>,<sep>,<pad>,<mask>,<eod> '\n",
        "\t             '--user_defined_symbols=<eop>,.,(,),\",-,–,£,€ ').format(\n",
        "               RAW_DATA_FPATH,\n",
        "               MODEL_PREFIX,\n",
        "               VOC_SIZE,\n",
        "               COVERAGE)\n",
        "spm.SentencePieceTrainer.Train(SPM_COMMAND)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OqMoEOjvIVPV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#import sentencepiece as spm\n",
        "#spm.SentencePieceTrainer.Train(\"--input=T-news_sohusite_xml.smarty.txt --model_prefix=sp10m.cased.v3 --vocab_size=3000 --character_coverage=0.99995 --model_type=unigram --control_symbols=<cls>,<sep>,<pad>,<mask>,<eod> --user_defined_symbols=<eop>,.,(,),“,”,-,£,€ --shuffle_input_sentence --input_sentence_size=10000\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0siGRV3uyjd2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "! cp T-news_sohusite_xml_xml.txt /content/xlnet_train/xlnet\n",
        "! mv /content/drive/data/sp10m.cased.v3.model /content/xlnet_train/xlnet\n",
        "! mv /content/drive/data/sp10m.cased.v3.vocab /content/xlnet_train/xlnet"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CC5USj4Kylz-",
        "colab_type": "code",
        "outputId": "b96a8017-8201-4470-995a-d573743f3a2b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "cd /content/xlnet_train/xlnet"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/xlnet_train/xlnet\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SCYuZlD0is-R",
        "colab_type": "code",
        "outputId": "9f820676-7e23-4239-f171-531eb5123154",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 469
        }
      },
      "source": [
        "pip install tensorflow-gpu==1.14"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting tensorflow-gpu==1.14\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/76/04/43153bfdfcf6c9a4c38ecdb971ca9a75b9a791bb69a764d652c359aca504/tensorflow_gpu-1.14.0-cp36-cp36m-manylinux1_x86_64.whl (377.0MB)\n",
            "\u001b[K     |████████████████████████████████| 377.0MB 109kB/s \n",
            "\u001b[?25hRequirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.14) (1.1.0)\n",
            "Requirement already satisfied: tensorflow-estimator<1.15.0rc0,>=1.14.0rc0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.14) (1.14.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.14) (1.1.0)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.14) (0.7.1)\n",
            "Requirement already satisfied: numpy<2.0,>=1.14.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.14) (1.16.4)\n",
            "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.14) (3.7.1)\n",
            "Requirement already satisfied: tensorboard<1.15.0,>=1.14.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.14) (1.14.0)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.14) (1.11.2)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.14) (1.15.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.14) (0.1.7)\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.14) (0.8.0)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.14) (1.12.0)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.14) (0.33.4)\n",
            "Requirement already satisfied: keras-applications>=1.0.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.14) (1.0.8)\n",
            "Requirement already satisfied: gast>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.14) (0.2.2)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.6.1->tensorflow-gpu==1.14) (41.0.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.15.0,>=1.14.0->tensorflow-gpu==1.14) (3.1.1)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.15.0,>=1.14.0->tensorflow-gpu==1.14) (0.15.5)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications>=1.0.6->tensorflow-gpu==1.14) (2.8.0)\n",
            "Installing collected packages: tensorflow-gpu\n",
            "Successfully installed tensorflow-gpu-1.14.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TRysZlc4wxnl",
        "colab_type": "code",
        "outputId": "2a1fecc3-fa30-4156-dc2e-90dde0f3017a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "comond = \"python data_utils.py \\\n",
        "\t--bsz_per_host=8 \\\n",
        "\t--num_core_per_host=1 \\\n",
        "\t--seq_len=128 \\\n",
        "\t--reuse_len=64 \\\n",
        "\t--input_glob=T-news_sohusite_xml_xml.txt \\\n",
        "\t--save_dir=tf_info\\\n",
        "  --num_passes=20 \\\n",
        "\t--bi_data=False \\\n",
        "\t--sp_path=sp10m.cased.v3.model \\\n",
        "\t--mask_alpha=6 \\\n",
        "\t--mask_beta=1 \\\n",
        "\t--num_predict=21 \\\n",
        "\t--learning_rate=0.01\"\n",
        "!{comond}"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING: Logging before flag parsing goes to stderr.\n",
            "W0809 01:33:08.239420 140415303137152 deprecation_wrapper.py:119] From data_utils.py:914: The name tf.logging.set_verbosity is deprecated. Please use tf.compat.v1.logging.set_verbosity instead.\n",
            "\n",
            "W0809 01:33:08.239699 140415303137152 deprecation_wrapper.py:119] From data_utils.py:914: The name tf.logging.INFO is deprecated. Please use tf.compat.v1.logging.INFO instead.\n",
            "\n",
            "W0809 01:33:08.239854 140415303137152 deprecation_wrapper.py:119] From data_utils.py:915: The name tf.app.run is deprecated. Please use tf.compat.v1.app.run instead.\n",
            "\n",
            "W0809 01:33:08.240417 140415303137152 deprecation_wrapper.py:119] From data_utils.py:181: The name tf.gfile.Exists is deprecated. Please use tf.io.gfile.exists instead.\n",
            "\n",
            "W0809 01:33:08.240619 140415303137152 deprecation_wrapper.py:119] From data_utils.py:182: The name tf.gfile.MakeDirs is deprecated. Please use tf.io.gfile.makedirs instead.\n",
            "\n",
            "W0809 01:33:08.240997 140415303137152 deprecation_wrapper.py:119] From data_utils.py:206: The name tf.gfile.Open is deprecated. Please use tf.io.gfile.GFile instead.\n",
            "\n",
            "W0809 01:33:08.241475 140415303137152 deprecation_wrapper.py:119] From data_utils.py:210: The name tf.gfile.Glob is deprecated. Please use tf.io.gfile.glob instead.\n",
            "\n",
            "W0809 01:33:08.243144 140415303137152 deprecation_wrapper.py:119] From data_utils.py:211: The name tf.logging.info is deprecated. Please use tf.compat.v1.logging.info instead.\n",
            "\n",
            "I0809 01:33:08.243388 140415303137152 data_utils.py:211] Use glob: T-news_sohusite_xml_xml.txt\n",
            "I0809 01:33:08.244271 140415303137152 data_utils.py:212] Find 1 files: ['./T-news_sohusite_xml_xml.txt']\n",
            "I0809 01:33:08.244376 140415303137152 data_utils.py:220] Task 0 process 1 files: ['./T-news_sohusite_xml_xml.txt']\n",
            "I0809 01:33:08.250086 140415303137152 data_utils.py:89] Processing ./T-news_sohusite_xml_xml.txt\n",
            "I0809 01:33:08.250886 140415303137152 data_utils.py:92] Loading line 0\n",
            "I0809 01:33:37.234844 140415303137152 data_utils.py:92] Loading line 100000\n",
            "I0809 01:34:06.007939 140415303137152 data_utils.py:92] Loading line 200000\n",
            "I0809 01:34:35.409434 140415303137152 data_utils.py:92] Loading line 300000\n",
            "I0809 01:35:07.164003 140415303137152 data_utils.py:92] Loading line 400000\n",
            "I0809 01:35:38.716544 140415303137152 data_utils.py:92] Loading line 500000\n",
            "I0809 01:36:09.257581 140415303137152 data_utils.py:92] Loading line 600000\n",
            "I0809 01:36:39.125356 140415303137152 data_utils.py:92] Loading line 700000\n",
            "I0809 01:37:07.365574 140415303137152 data_utils.py:92] Loading line 800000\n",
            "tcmalloc: large alloc 1233903616 bytes == 0x5ae8000 @  0x7fb4fc008615 0x56f125 0x4f862c 0x4f98c7 0x4f7a28 0x4f876d 0x4f98c7 0x4f7a28 0x4f876d 0x4f98c7 0x4f7a28 0x4f876d 0x4f98c7 0x4f6128 0x4f7d60 0x4f876d 0x4fa6c0 0x4f6128 0x4f7d60 0x4f876d 0x4f98c7 0x4f6128 0x4f9023 0x6415b2 0x64166a 0x643730 0x62b26e 0x4b4cb0 0x7fb4fbc04b97 0x5bdf6a\n",
            "tcmalloc: large alloc 1233903616 bytes == 0x7fbb2000 @  0x7fb4fc008615 0x56f125 0x4f862c 0x4f98c7 0x4f7a28 0x4f876d 0x4f98c7 0x4f7a28 0x4f876d 0x4f98c7 0x4f7a28 0x4f876d 0x4f98c7 0x4f6128 0x4f7d60 0x4f876d 0x4fa6c0 0x4f6128 0x4f7d60 0x4f876d 0x4f98c7 0x4f6128 0x4f9023 0x6415b2 0x64166a 0x643730 0x62b26e 0x4b4cb0 0x7fb4fbc04b97 0x5bdf6a\n",
            "I0809 01:37:35.801820 140415303137152 data_utils.py:92] Loading line 900000\n",
            "I0809 01:38:03.910655 140415303137152 data_utils.py:112] Finish with line 1000000\n",
            "I0809 01:38:20.684344 140415303137152 data_utils.py:122] [Task 0] Total number line: 1000000\n",
            "I0809 01:38:20.692858 140415303137152 data_utils.py:133] Using perm indices [0] for pass 0\n",
            "I0809 01:38:21.001969 140415303137152 data_utils.py:419] Raw data shape (8, 16772244).\n",
            "W0809 01:38:21.002344 140415303137152 deprecation_wrapper.py:119] From data_utils.py:434: The name tf.python_io.TFRecordWriter is deprecated. Please use tf.io.TFRecordWriter instead.\n",
            "\n",
            "I0809 01:38:21.002705 140415303137152 data_utils.py:435] Start writing tf_info/tfrecords/train-0-0.bsz-8.seqlen-128.reuse-64.uncased.uni.alpha-6.beta-1.fnp-21.tfrecords.\n",
            "I0809 01:38:21.002882 140415303137152 data_utils.py:450] Processing batch 0\n",
            "I0809 01:38:33.197543 140415303137152 data_utils.py:450] Processing batch 500\n",
            "I0809 01:38:45.389894 140415303137152 data_utils.py:450] Processing batch 1000\n",
            "I0809 01:38:57.755094 140415303137152 data_utils.py:450] Processing batch 1500\n",
            "I0809 01:39:10.012702 140415303137152 data_utils.py:450] Processing batch 2000\n",
            "I0809 01:39:22.645115 140415303137152 data_utils.py:450] Processing batch 2500\n",
            "I0809 01:39:35.160442 140415303137152 data_utils.py:450] Processing batch 3000\n",
            "I0809 01:39:47.933075 140415303137152 data_utils.py:450] Processing batch 3500\n",
            "I0809 01:40:00.201857 140415303137152 data_utils.py:450] Processing batch 4000\n",
            "I0809 01:40:12.637733 140415303137152 data_utils.py:450] Processing batch 4500\n",
            "I0809 01:40:24.821910 140415303137152 data_utils.py:450] Processing batch 5000\n",
            "I0809 01:40:37.453729 140415303137152 data_utils.py:450] Processing batch 5500\n",
            "I0809 01:40:49.782692 140415303137152 data_utils.py:450] Processing batch 6000\n",
            "I0809 01:41:02.006071 140415303137152 data_utils.py:450] Processing batch 6500\n",
            "I0809 01:41:14.212895 140415303137152 data_utils.py:450] Processing batch 7000\n",
            "I0809 01:41:26.195191 140415303137152 data_utils.py:450] Processing batch 7500\n",
            "I0809 01:41:38.627360 140415303137152 data_utils.py:450] Processing batch 8000\n",
            "I0809 01:41:50.904383 140415303137152 data_utils.py:450] Processing batch 8500\n",
            "I0809 01:42:02.997662 140415303137152 data_utils.py:450] Processing batch 9000\n",
            "I0809 01:42:15.267931 140415303137152 data_utils.py:450] Processing batch 9500\n",
            "I0809 01:42:27.775105 140415303137152 data_utils.py:450] Processing batch 10000\n",
            "I0809 01:42:40.125123 140415303137152 data_utils.py:450] Processing batch 10500\n",
            "I0809 01:42:52.273793 140415303137152 data_utils.py:450] Processing batch 11000\n",
            "I0809 01:43:04.780167 140415303137152 data_utils.py:450] Processing batch 11500\n",
            "I0809 01:43:17.105060 140415303137152 data_utils.py:450] Processing batch 12000\n",
            "I0809 01:43:29.426211 140415303137152 data_utils.py:450] Processing batch 12500\n",
            "I0809 01:43:41.614169 140415303137152 data_utils.py:450] Processing batch 13000\n",
            "I0809 01:43:53.590771 140415303137152 data_utils.py:450] Processing batch 13500\n",
            "I0809 01:44:05.664876 140415303137152 data_utils.py:450] Processing batch 14000\n",
            "I0809 01:44:18.070929 140415303137152 data_utils.py:450] Processing batch 14500\n",
            "I0809 01:44:30.167818 140415303137152 data_utils.py:450] Processing batch 15000\n",
            "I0809 01:44:42.460665 140415303137152 data_utils.py:450] Processing batch 15500\n",
            "I0809 01:44:54.666219 140415303137152 data_utils.py:450] Processing batch 16000\n",
            "I0809 01:45:06.843760 140415303137152 data_utils.py:450] Processing batch 16500\n",
            "I0809 01:45:19.121894 140415303137152 data_utils.py:450] Processing batch 17000\n",
            "I0809 01:45:31.269305 140415303137152 data_utils.py:450] Processing batch 17500\n",
            "I0809 01:45:43.705545 140415303137152 data_utils.py:450] Processing batch 18000\n",
            "I0809 01:45:56.074199 140415303137152 data_utils.py:450] Processing batch 18500\n",
            "I0809 01:46:08.337776 140415303137152 data_utils.py:450] Processing batch 19000\n",
            "I0809 01:46:20.526185 140415303137152 data_utils.py:450] Processing batch 19500\n",
            "I0809 01:46:32.850755 140415303137152 data_utils.py:450] Processing batch 20000\n",
            "I0809 01:46:45.078367 140415303137152 data_utils.py:450] Processing batch 20500\n",
            "I0809 01:46:57.430335 140415303137152 data_utils.py:450] Processing batch 21000\n",
            "I0809 01:47:09.719473 140415303137152 data_utils.py:450] Processing batch 21500\n",
            "I0809 01:47:22.293279 140415303137152 data_utils.py:450] Processing batch 22000\n",
            "I0809 01:47:34.734565 140415303137152 data_utils.py:450] Processing batch 22500\n",
            "I0809 01:47:47.081894 140415303137152 data_utils.py:450] Processing batch 23000\n",
            "I0809 01:47:59.545097 140415303137152 data_utils.py:450] Processing batch 23500\n",
            "I0809 01:48:11.902548 140415303137152 data_utils.py:450] Processing batch 24000\n",
            "I0809 01:48:24.259764 140415303137152 data_utils.py:450] Processing batch 24500\n",
            "I0809 01:48:36.690716 140415303137152 data_utils.py:450] Processing batch 25000\n",
            "I0809 01:48:49.012921 140415303137152 data_utils.py:450] Processing batch 25500\n",
            "I0809 01:49:01.365007 140415303137152 data_utils.py:450] Processing batch 26000\n",
            "I0809 01:49:13.813437 140415303137152 data_utils.py:450] Processing batch 26500\n",
            "I0809 01:49:26.078179 140415303137152 data_utils.py:450] Processing batch 27000\n",
            "I0809 01:49:38.416126 140415303137152 data_utils.py:450] Processing batch 27500\n",
            "I0809 01:49:50.944062 140415303137152 data_utils.py:450] Processing batch 28000\n",
            "I0809 01:50:03.263904 140415303137152 data_utils.py:450] Processing batch 28500\n",
            "I0809 01:50:15.748114 140415303137152 data_utils.py:450] Processing batch 29000\n",
            "I0809 01:50:27.934053 140415303137152 data_utils.py:450] Processing batch 29500\n",
            "I0809 01:50:40.267359 140415303137152 data_utils.py:450] Processing batch 30000\n",
            "I0809 01:50:52.399491 140415303137152 data_utils.py:450] Processing batch 30500\n",
            "I0809 01:51:04.580494 140415303137152 data_utils.py:450] Processing batch 31000\n",
            "I0809 01:51:16.639229 140415303137152 data_utils.py:450] Processing batch 31500\n",
            "I0809 01:51:28.682776 140415303137152 data_utils.py:450] Processing batch 32000\n",
            "I0809 01:51:41.006318 140415303137152 data_utils.py:450] Processing batch 32500\n",
            "I0809 01:51:53.239732 140415303137152 data_utils.py:450] Processing batch 33000\n",
            "I0809 01:52:05.300954 140415303137152 data_utils.py:450] Processing batch 33500\n",
            "I0809 01:52:17.805201 140415303137152 data_utils.py:450] Processing batch 34000\n",
            "I0809 01:52:30.176481 140415303137152 data_utils.py:450] Processing batch 34500\n",
            "I0809 01:52:42.839839 140415303137152 data_utils.py:450] Processing batch 35000\n",
            "I0809 01:52:55.019484 140415303137152 data_utils.py:450] Processing batch 35500\n",
            "I0809 01:53:07.231986 140415303137152 data_utils.py:450] Processing batch 36000\n",
            "I0809 01:53:19.613690 140415303137152 data_utils.py:450] Processing batch 36500\n",
            "I0809 01:53:32.229434 140415303137152 data_utils.py:450] Processing batch 37000\n",
            "I0809 01:53:44.497878 140415303137152 data_utils.py:450] Processing batch 37500\n",
            "I0809 01:53:57.159799 140415303137152 data_utils.py:450] Processing batch 38000\n",
            "I0809 01:54:09.763490 140415303137152 data_utils.py:450] Processing batch 38500\n",
            "I0809 01:54:22.127924 140415303137152 data_utils.py:450] Processing batch 39000\n",
            "I0809 01:54:34.368079 140415303137152 data_utils.py:450] Processing batch 39500\n",
            "I0809 01:54:46.690401 140415303137152 data_utils.py:450] Processing batch 40000\n",
            "I0809 01:54:59.276945 140415303137152 data_utils.py:450] Processing batch 40500\n",
            "I0809 01:55:11.570473 140415303137152 data_utils.py:450] Processing batch 41000\n",
            "I0809 01:55:23.731670 140415303137152 data_utils.py:450] Processing batch 41500\n",
            "I0809 01:55:35.830198 140415303137152 data_utils.py:450] Processing batch 42000\n",
            "I0809 01:55:47.968061 140415303137152 data_utils.py:450] Processing batch 42500\n",
            "I0809 01:56:00.116630 140415303137152 data_utils.py:450] Processing batch 43000\n",
            "I0809 01:56:12.309235 140415303137152 data_utils.py:450] Processing batch 43500\n",
            "I0809 01:56:24.496392 140415303137152 data_utils.py:450] Processing batch 44000\n",
            "I0809 01:56:36.772818 140415303137152 data_utils.py:450] Processing batch 44500\n",
            "I0809 01:56:49.064657 140415303137152 data_utils.py:450] Processing batch 45000\n",
            "I0809 01:57:01.404469 140415303137152 data_utils.py:450] Processing batch 45500\n",
            "I0809 01:57:13.824485 140415303137152 data_utils.py:450] Processing batch 46000\n",
            "I0809 01:57:26.302043 140415303137152 data_utils.py:450] Processing batch 46500\n",
            "I0809 01:57:38.661826 140415303137152 data_utils.py:450] Processing batch 47000\n",
            "I0809 01:57:51.062729 140415303137152 data_utils.py:450] Processing batch 47500\n",
            "I0809 01:58:03.418442 140415303137152 data_utils.py:450] Processing batch 48000\n",
            "I0809 01:58:15.725423 140415303137152 data_utils.py:450] Processing batch 48500\n",
            "I0809 01:58:28.141722 140415303137152 data_utils.py:450] Processing batch 49000\n",
            "I0809 01:58:40.460451 140415303137152 data_utils.py:450] Processing batch 49500\n",
            "I0809 01:58:52.630090 140415303137152 data_utils.py:450] Processing batch 50000\n",
            "I0809 01:59:04.963141 140415303137152 data_utils.py:450] Processing batch 50500\n",
            "I0809 01:59:17.350022 140415303137152 data_utils.py:450] Processing batch 51000\n",
            "I0809 01:59:29.178974 140415303137152 data_utils.py:450] Processing batch 51500\n",
            "I0809 01:59:41.017855 140415303137152 data_utils.py:450] Processing batch 52000\n",
            "I0809 01:59:53.083234 140415303137152 data_utils.py:450] Processing batch 52500\n",
            "I0809 02:00:05.204687 140415303137152 data_utils.py:450] Processing batch 53000\n",
            "I0809 02:00:17.418720 140415303137152 data_utils.py:450] Processing batch 53500\n",
            "I0809 02:00:29.952976 140415303137152 data_utils.py:450] Processing batch 54000\n",
            "I0809 02:00:42.255533 140415303137152 data_utils.py:450] Processing batch 54500\n",
            "I0809 02:00:54.641764 140415303137152 data_utils.py:450] Processing batch 55000\n",
            "I0809 02:01:07.076753 140415303137152 data_utils.py:450] Processing batch 55500\n",
            "I0809 02:01:19.271848 140415303137152 data_utils.py:450] Processing batch 56000\n",
            "I0809 02:01:31.686574 140415303137152 data_utils.py:450] Processing batch 56500\n",
            "I0809 02:01:43.928005 140415303137152 data_utils.py:450] Processing batch 57000\n",
            "I0809 02:01:56.371986 140415303137152 data_utils.py:450] Processing batch 57500\n",
            "I0809 02:02:08.897563 140415303137152 data_utils.py:450] Processing batch 58000\n",
            "I0809 02:02:21.021210 140415303137152 data_utils.py:450] Processing batch 58500\n",
            "I0809 02:02:33.208599 140415303137152 data_utils.py:450] Processing batch 59000\n",
            "I0809 02:02:45.387520 140415303137152 data_utils.py:450] Processing batch 59500\n",
            "I0809 02:02:57.679324 140415303137152 data_utils.py:450] Processing batch 60000\n",
            "I0809 02:03:09.925149 140415303137152 data_utils.py:450] Processing batch 60500\n",
            "I0809 02:03:22.158601 140415303137152 data_utils.py:450] Processing batch 61000\n",
            "I0809 02:03:34.385076 140415303137152 data_utils.py:450] Processing batch 61500\n",
            "I0809 02:03:46.619341 140415303137152 data_utils.py:450] Processing batch 62000\n",
            "I0809 02:03:58.758457 140415303137152 data_utils.py:450] Processing batch 62500\n",
            "I0809 02:04:11.104154 140415303137152 data_utils.py:450] Processing batch 63000\n",
            "I0809 02:04:23.442727 140415303137152 data_utils.py:450] Processing batch 63500\n",
            "I0809 02:04:35.907578 140415303137152 data_utils.py:450] Processing batch 64000\n",
            "I0809 02:04:48.393002 140415303137152 data_utils.py:450] Processing batch 64500\n",
            "I0809 02:05:00.848547 140415303137152 data_utils.py:450] Processing batch 65000\n",
            "I0809 02:05:13.070611 140415303137152 data_utils.py:450] Processing batch 65500\n",
            "I0809 02:05:25.487338 140415303137152 data_utils.py:450] Processing batch 66000\n",
            "I0809 02:05:38.149738 140415303137152 data_utils.py:450] Processing batch 66500\n",
            "I0809 02:05:50.686880 140415303137152 data_utils.py:450] Processing batch 67000\n",
            "I0809 02:06:03.128092 140415303137152 data_utils.py:450] Processing batch 67500\n",
            "I0809 02:06:15.396191 140415303137152 data_utils.py:450] Processing batch 68000\n",
            "I0809 02:06:27.479774 140415303137152 data_utils.py:450] Processing batch 68500\n",
            "I0809 02:06:39.872878 140415303137152 data_utils.py:450] Processing batch 69000\n",
            "I0809 02:06:52.216982 140415303137152 data_utils.py:450] Processing batch 69500\n",
            "I0809 02:07:04.351944 140415303137152 data_utils.py:450] Processing batch 70000\n",
            "I0809 02:07:16.454564 140415303137152 data_utils.py:450] Processing batch 70500\n",
            "I0809 02:07:28.696738 140415303137152 data_utils.py:450] Processing batch 71000\n",
            "I0809 02:07:40.937594 140415303137152 data_utils.py:450] Processing batch 71500\n",
            "I0809 02:07:53.467864 140415303137152 data_utils.py:450] Processing batch 72000\n",
            "I0809 02:08:05.474528 140415303137152 data_utils.py:450] Processing batch 72500\n",
            "I0809 02:08:17.619203 140415303137152 data_utils.py:450] Processing batch 73000\n",
            "I0809 02:08:29.893066 140415303137152 data_utils.py:450] Processing batch 73500\n",
            "I0809 02:08:42.229106 140415303137152 data_utils.py:450] Processing batch 74000\n",
            "I0809 02:08:54.608039 140415303137152 data_utils.py:450] Processing batch 74500\n",
            "I0809 02:09:07.080182 140415303137152 data_utils.py:450] Processing batch 75000\n",
            "I0809 02:09:19.420469 140415303137152 data_utils.py:450] Processing batch 75500\n",
            "I0809 02:09:31.729562 140415303137152 data_utils.py:450] Processing batch 76000\n",
            "I0809 02:09:43.755379 140415303137152 data_utils.py:450] Processing batch 76500\n",
            "I0809 02:09:56.031630 140415303137152 data_utils.py:450] Processing batch 77000\n",
            "I0809 02:10:08.107655 140415303137152 data_utils.py:450] Processing batch 77500\n",
            "I0809 02:10:20.155745 140415303137152 data_utils.py:450] Processing batch 78000\n",
            "I0809 02:10:32.312183 140415303137152 data_utils.py:450] Processing batch 78500\n",
            "I0809 02:10:44.609512 140415303137152 data_utils.py:450] Processing batch 79000\n",
            "I0809 02:10:57.174432 140415303137152 data_utils.py:450] Processing batch 79500\n",
            "I0809 02:11:09.776338 140415303137152 data_utils.py:450] Processing batch 80000\n",
            "I0809 02:11:22.503703 140415303137152 data_utils.py:450] Processing batch 80500\n",
            "I0809 02:11:35.160123 140415303137152 data_utils.py:450] Processing batch 81000\n",
            "I0809 02:11:47.736999 140415303137152 data_utils.py:450] Processing batch 81500\n",
            "I0809 02:12:00.548437 140415303137152 data_utils.py:450] Processing batch 82000\n",
            "I0809 02:12:12.945190 140415303137152 data_utils.py:450] Processing batch 82500\n",
            "I0809 02:12:25.394101 140415303137152 data_utils.py:450] Processing batch 83000\n",
            "I0809 02:12:37.840804 140415303137152 data_utils.py:450] Processing batch 83500\n",
            "I0809 02:12:50.218174 140415303137152 data_utils.py:450] Processing batch 84000\n",
            "I0809 02:13:02.358700 140415303137152 data_utils.py:450] Processing batch 84500\n",
            "I0809 02:13:14.469822 140415303137152 data_utils.py:450] Processing batch 85000\n",
            "I0809 02:13:26.674328 140415303137152 data_utils.py:450] Processing batch 85500\n",
            "I0809 02:13:38.991199 140415303137152 data_utils.py:450] Processing batch 86000\n",
            "I0809 02:13:51.448864 140415303137152 data_utils.py:450] Processing batch 86500\n",
            "I0809 02:14:03.558367 140415303137152 data_utils.py:450] Processing batch 87000\n",
            "I0809 02:14:16.152224 140415303137152 data_utils.py:450] Processing batch 87500\n",
            "I0809 02:14:28.517197 140415303137152 data_utils.py:450] Processing batch 88000\n",
            "I0809 02:14:40.768475 140415303137152 data_utils.py:450] Processing batch 88500\n",
            "I0809 02:14:52.829665 140415303137152 data_utils.py:450] Processing batch 89000\n",
            "I0809 02:15:05.001487 140415303137152 data_utils.py:450] Processing batch 89500\n",
            "I0809 02:15:17.288012 140415303137152 data_utils.py:450] Processing batch 90000\n",
            "I0809 02:15:29.613853 140415303137152 data_utils.py:450] Processing batch 90500\n",
            "I0809 02:15:42.167154 140415303137152 data_utils.py:450] Processing batch 91000\n",
            "I0809 02:15:54.479672 140415303137152 data_utils.py:450] Processing batch 91500\n",
            "I0809 02:16:06.651490 140415303137152 data_utils.py:450] Processing batch 92000\n",
            "I0809 02:16:18.906828 140415303137152 data_utils.py:450] Processing batch 92500\n",
            "I0809 02:16:31.282887 140415303137152 data_utils.py:450] Processing batch 93000\n",
            "I0809 02:16:43.492054 140415303137152 data_utils.py:450] Processing batch 93500\n",
            "I0809 02:16:55.639223 140415303137152 data_utils.py:450] Processing batch 94000\n",
            "I0809 02:17:07.908670 140415303137152 data_utils.py:450] Processing batch 94500\n",
            "I0809 02:17:20.280269 140415303137152 data_utils.py:450] Processing batch 95000\n",
            "I0809 02:17:32.684108 140415303137152 data_utils.py:450] Processing batch 95500\n",
            "I0809 02:17:45.057861 140415303137152 data_utils.py:450] Processing batch 96000\n",
            "I0809 02:17:57.862761 140415303137152 data_utils.py:450] Processing batch 96500\n",
            "I0809 02:18:10.155247 140415303137152 data_utils.py:450] Processing batch 97000\n",
            "I0809 02:18:22.410249 140415303137152 data_utils.py:450] Processing batch 97500\n",
            "I0809 02:18:34.870960 140415303137152 data_utils.py:450] Processing batch 98000\n",
            "I0809 02:18:47.407341 140415303137152 data_utils.py:450] Processing batch 98500\n",
            "I0809 02:18:59.881706 140415303137152 data_utils.py:450] Processing batch 99000\n",
            "I0809 02:19:12.262138 140415303137152 data_utils.py:450] Processing batch 99500\n",
            "I0809 02:19:24.842800 140415303137152 data_utils.py:450] Processing batch 100000\n",
            "I0809 02:19:36.959233 140415303137152 data_utils.py:450] Processing batch 100500\n",
            "I0809 02:19:49.437345 140415303137152 data_utils.py:450] Processing batch 101000\n",
            "I0809 02:20:01.495887 140415303137152 data_utils.py:450] Processing batch 101500\n",
            "I0809 02:20:13.392525 140415303137152 data_utils.py:450] Processing batch 102000\n",
            "I0809 02:20:25.952858 140415303137152 data_utils.py:450] Processing batch 102500\n",
            "I0809 02:20:38.670465 140415303137152 data_utils.py:450] Processing batch 103000\n",
            "I0809 02:20:51.167396 140415303137152 data_utils.py:450] Processing batch 103500\n",
            "I0809 02:21:03.639633 140415303137152 data_utils.py:450] Processing batch 104000\n",
            "I0809 02:21:16.040850 140415303137152 data_utils.py:450] Processing batch 104500\n",
            "I0809 02:21:28.449641 140415303137152 data_utils.py:450] Processing batch 105000\n",
            "I0809 02:21:40.733144 140415303137152 data_utils.py:450] Processing batch 105500\n",
            "I0809 02:21:53.124489 140415303137152 data_utils.py:450] Processing batch 106000\n",
            "I0809 02:22:05.190846 140415303137152 data_utils.py:450] Processing batch 106500\n",
            "I0809 02:22:17.447505 140415303137152 data_utils.py:450] Processing batch 107000\n",
            "I0809 02:22:29.577665 140415303137152 data_utils.py:450] Processing batch 107500\n",
            "I0809 02:22:41.666564 140415303137152 data_utils.py:450] Processing batch 108000\n",
            "I0809 02:22:53.862672 140415303137152 data_utils.py:450] Processing batch 108500\n",
            "I0809 02:23:05.922991 140415303137152 data_utils.py:450] Processing batch 109000\n",
            "I0809 02:23:18.195519 140415303137152 data_utils.py:450] Processing batch 109500\n",
            "I0809 02:23:30.601182 140415303137152 data_utils.py:450] Processing batch 110000\n",
            "I0809 02:23:42.889916 140415303137152 data_utils.py:450] Processing batch 110500\n",
            "I0809 02:23:55.211692 140415303137152 data_utils.py:450] Processing batch 111000\n",
            "I0809 02:24:07.407168 140415303137152 data_utils.py:450] Processing batch 111500\n",
            "I0809 02:24:19.450829 140415303137152 data_utils.py:450] Processing batch 112000\n",
            "I0809 02:24:31.675644 140415303137152 data_utils.py:450] Processing batch 112500\n",
            "I0809 02:24:43.674695 140415303137152 data_utils.py:450] Processing batch 113000\n",
            "I0809 02:24:55.779726 140415303137152 data_utils.py:450] Processing batch 113500\n",
            "I0809 02:25:07.745738 140415303137152 data_utils.py:450] Processing batch 114000\n",
            "I0809 02:25:19.855349 140415303137152 data_utils.py:450] Processing batch 114500\n",
            "I0809 02:25:32.353040 140415303137152 data_utils.py:450] Processing batch 115000\n",
            "I0809 02:25:44.619657 140415303137152 data_utils.py:450] Processing batch 115500\n",
            "I0809 02:25:56.662707 140415303137152 data_utils.py:450] Processing batch 116000\n",
            "I0809 02:26:08.935145 140415303137152 data_utils.py:450] Processing batch 116500\n",
            "I0809 02:26:21.202805 140415303137152 data_utils.py:450] Processing batch 117000\n",
            "I0809 02:26:33.304077 140415303137152 data_utils.py:450] Processing batch 117500\n",
            "I0809 02:26:45.530291 140415303137152 data_utils.py:450] Processing batch 118000\n",
            "I0809 02:26:57.638194 140415303137152 data_utils.py:450] Processing batch 118500\n",
            "I0809 02:27:10.101543 140415303137152 data_utils.py:450] Processing batch 119000\n",
            "I0809 02:27:22.743813 140415303137152 data_utils.py:450] Processing batch 119500\n",
            "I0809 02:27:35.277196 140415303137152 data_utils.py:450] Processing batch 120000\n",
            "I0809 02:27:47.664836 140415303137152 data_utils.py:450] Processing batch 120500\n",
            "I0809 02:27:59.898477 140415303137152 data_utils.py:450] Processing batch 121000\n",
            "I0809 02:28:12.017301 140415303137152 data_utils.py:450] Processing batch 121500\n",
            "I0809 02:28:24.333603 140415303137152 data_utils.py:450] Processing batch 122000\n",
            "I0809 02:28:36.573364 140415303137152 data_utils.py:450] Processing batch 122500\n",
            "I0809 02:28:48.737449 140415303137152 data_utils.py:450] Processing batch 123000\n",
            "I0809 02:29:00.670922 140415303137152 data_utils.py:450] Processing batch 123500\n",
            "I0809 02:29:13.027173 140415303137152 data_utils.py:450] Processing batch 124000\n",
            "I0809 02:29:25.498619 140415303137152 data_utils.py:450] Processing batch 124500\n",
            "I0809 02:29:37.895350 140415303137152 data_utils.py:450] Processing batch 125000\n",
            "I0809 02:29:50.231807 140415303137152 data_utils.py:450] Processing batch 125500\n",
            "I0809 02:30:02.550455 140415303137152 data_utils.py:450] Processing batch 126000\n",
            "I0809 02:30:14.937920 140415303137152 data_utils.py:450] Processing batch 126500\n",
            "I0809 02:30:27.246522 140415303137152 data_utils.py:450] Processing batch 127000\n",
            "I0809 02:30:39.461742 140415303137152 data_utils.py:450] Processing batch 127500\n",
            "I0809 02:30:51.864513 140415303137152 data_utils.py:450] Processing batch 128000\n",
            "I0809 02:31:04.180965 140415303137152 data_utils.py:450] Processing batch 128500\n",
            "I0809 02:31:16.621320 140415303137152 data_utils.py:450] Processing batch 129000\n",
            "I0809 02:31:28.913176 140415303137152 data_utils.py:450] Processing batch 129500\n",
            "I0809 02:31:41.120331 140415303137152 data_utils.py:450] Processing batch 130000\n",
            "I0809 02:31:53.649409 140415303137152 data_utils.py:450] Processing batch 130500\n",
            "I0809 02:32:06.114422 140415303137152 data_utils.py:450] Processing batch 131000\n",
            "I0809 02:32:18.171560 140415303137152 data_utils.py:450] Processing batch 131500\n",
            "I0809 02:32:30.379261 140415303137152 data_utils.py:450] Processing batch 132000\n",
            "I0809 02:32:42.576529 140415303137152 data_utils.py:450] Processing batch 132500\n",
            "I0809 02:32:54.588050 140415303137152 data_utils.py:450] Processing batch 133000\n",
            "I0809 02:33:06.666180 140415303137152 data_utils.py:450] Processing batch 133500\n",
            "I0809 02:33:18.614061 140415303137152 data_utils.py:450] Processing batch 134000\n",
            "I0809 02:33:30.712434 140415303137152 data_utils.py:450] Processing batch 134500\n",
            "I0809 02:33:42.637240 140415303137152 data_utils.py:450] Processing batch 135000\n",
            "I0809 02:33:55.307687 140415303137152 data_utils.py:450] Processing batch 135500\n",
            "I0809 02:34:07.865560 140415303137152 data_utils.py:450] Processing batch 136000\n",
            "I0809 02:34:20.035814 140415303137152 data_utils.py:450] Processing batch 136500\n",
            "I0809 02:34:32.532450 140415303137152 data_utils.py:450] Processing batch 137000\n",
            "I0809 02:34:44.710047 140415303137152 data_utils.py:450] Processing batch 137500\n",
            "I0809 02:34:57.146467 140415303137152 data_utils.py:450] Processing batch 138000\n",
            "I0809 02:35:09.489179 140415303137152 data_utils.py:450] Processing batch 138500\n",
            "I0809 02:35:21.900057 140415303137152 data_utils.py:450] Processing batch 139000\n",
            "I0809 02:35:33.981773 140415303137152 data_utils.py:450] Processing batch 139500\n",
            "I0809 02:35:46.420696 140415303137152 data_utils.py:450] Processing batch 140000\n",
            "I0809 02:35:58.819620 140415303137152 data_utils.py:450] Processing batch 140500\n",
            "I0809 02:36:10.892831 140415303137152 data_utils.py:450] Processing batch 141000\n",
            "I0809 02:36:22.885332 140415303137152 data_utils.py:450] Processing batch 141500\n",
            "I0809 02:36:35.104321 140415303137152 data_utils.py:450] Processing batch 142000\n",
            "I0809 02:36:47.473713 140415303137152 data_utils.py:450] Processing batch 142500\n",
            "I0809 02:36:59.677660 140415303137152 data_utils.py:450] Processing batch 143000\n",
            "I0809 02:37:11.726541 140415303137152 data_utils.py:450] Processing batch 143500\n",
            "I0809 02:37:23.905655 140415303137152 data_utils.py:450] Processing batch 144000\n",
            "I0809 02:37:36.442505 140415303137152 data_utils.py:450] Processing batch 144500\n",
            "I0809 02:37:48.777287 140415303137152 data_utils.py:450] Processing batch 145000\n",
            "I0809 02:38:01.389435 140415303137152 data_utils.py:450] Processing batch 145500\n",
            "I0809 02:38:13.719441 140415303137152 data_utils.py:450] Processing batch 146000\n",
            "I0809 02:38:26.154601 140415303137152 data_utils.py:450] Processing batch 146500\n",
            "I0809 02:38:38.740823 140415303137152 data_utils.py:450] Processing batch 147000\n",
            "I0809 02:38:51.172713 140415303137152 data_utils.py:450] Processing batch 147500\n",
            "I0809 02:39:03.697175 140415303137152 data_utils.py:450] Processing batch 148000\n",
            "I0809 02:39:16.116757 140415303137152 data_utils.py:450] Processing batch 148500\n",
            "I0809 02:39:28.643638 140415303137152 data_utils.py:450] Processing batch 149000\n",
            "I0809 02:39:40.710402 140415303137152 data_utils.py:450] Processing batch 149500\n",
            "I0809 02:39:52.676144 140415303137152 data_utils.py:450] Processing batch 150000\n",
            "I0809 02:40:04.885292 140415303137152 data_utils.py:450] Processing batch 150500\n",
            "I0809 02:40:17.368683 140415303137152 data_utils.py:450] Processing batch 151000\n",
            "I0809 02:40:29.768871 140415303137152 data_utils.py:450] Processing batch 151500\n",
            "I0809 02:40:42.258242 140415303137152 data_utils.py:450] Processing batch 152000\n",
            "I0809 02:40:54.836095 140415303137152 data_utils.py:450] Processing batch 152500\n",
            "I0809 02:41:07.627381 140415303137152 data_utils.py:450] Processing batch 153000\n",
            "I0809 02:41:19.889531 140415303137152 data_utils.py:450] Processing batch 153500\n",
            "I0809 02:41:31.988109 140415303137152 data_utils.py:450] Processing batch 154000\n",
            "I0809 02:41:44.271018 140415303137152 data_utils.py:450] Processing batch 154500\n",
            "I0809 02:41:56.543216 140415303137152 data_utils.py:450] Processing batch 155000\n",
            "I0809 02:42:08.768372 140415303137152 data_utils.py:450] Processing batch 155500\n",
            "I0809 02:42:21.002825 140415303137152 data_utils.py:450] Processing batch 156000\n",
            "I0809 02:42:33.141490 140415303137152 data_utils.py:450] Processing batch 156500\n",
            "I0809 02:42:45.457831 140415303137152 data_utils.py:450] Processing batch 157000\n",
            "I0809 02:42:57.801479 140415303137152 data_utils.py:450] Processing batch 157500\n",
            "I0809 02:43:10.133797 140415303137152 data_utils.py:450] Processing batch 158000\n",
            "I0809 02:43:22.726319 140415303137152 data_utils.py:450] Processing batch 158500\n",
            "I0809 02:43:35.001519 140415303137152 data_utils.py:450] Processing batch 159000\n",
            "I0809 02:43:47.108872 140415303137152 data_utils.py:450] Processing batch 159500\n",
            "I0809 02:43:59.269321 140415303137152 data_utils.py:450] Processing batch 160000\n",
            "I0809 02:44:11.372830 140415303137152 data_utils.py:450] Processing batch 160500\n",
            "I0809 02:44:23.821947 140415303137152 data_utils.py:450] Processing batch 161000\n",
            "I0809 02:44:36.372329 140415303137152 data_utils.py:450] Processing batch 161500\n",
            "I0809 02:44:48.812112 140415303137152 data_utils.py:450] Processing batch 162000\n",
            "I0809 02:45:01.404228 140415303137152 data_utils.py:450] Processing batch 162500\n",
            "I0809 02:45:13.752063 140415303137152 data_utils.py:450] Processing batch 163000\n",
            "I0809 02:45:26.101547 140415303137152 data_utils.py:450] Processing batch 163500\n",
            "I0809 02:45:38.407069 140415303137152 data_utils.py:450] Processing batch 164000\n",
            "I0809 02:45:50.609974 140415303137152 data_utils.py:450] Processing batch 164500\n",
            "I0809 02:46:02.822559 140415303137152 data_utils.py:450] Processing batch 165000\n",
            "I0809 02:46:14.934026 140415303137152 data_utils.py:450] Processing batch 165500\n",
            "I0809 02:46:27.221729 140415303137152 data_utils.py:450] Processing batch 166000\n",
            "I0809 02:46:39.389107 140415303137152 data_utils.py:450] Processing batch 166500\n",
            "I0809 02:46:51.454067 140415303137152 data_utils.py:450] Processing batch 167000\n",
            "I0809 02:47:03.401983 140415303137152 data_utils.py:450] Processing batch 167500\n",
            "I0809 02:47:15.314548 140415303137152 data_utils.py:450] Processing batch 168000\n",
            "I0809 02:47:27.408845 140415303137152 data_utils.py:450] Processing batch 168500\n",
            "I0809 02:47:39.517596 140415303137152 data_utils.py:450] Processing batch 169000\n",
            "I0809 02:47:51.737768 140415303137152 data_utils.py:450] Processing batch 169500\n",
            "I0809 02:48:03.872546 140415303137152 data_utils.py:450] Processing batch 170000\n",
            "I0809 02:48:16.237106 140415303137152 data_utils.py:450] Processing batch 170500\n",
            "I0809 02:48:28.635838 140415303137152 data_utils.py:450] Processing batch 171000\n",
            "I0809 02:48:40.790021 140415303137152 data_utils.py:450] Processing batch 171500\n",
            "I0809 02:48:53.053628 140415303137152 data_utils.py:450] Processing batch 172000\n",
            "I0809 02:49:05.340284 140415303137152 data_utils.py:450] Processing batch 172500\n",
            "I0809 02:49:17.512033 140415303137152 data_utils.py:450] Processing batch 173000\n",
            "I0809 02:49:29.960500 140415303137152 data_utils.py:450] Processing batch 173500\n",
            "I0809 02:49:42.324823 140415303137152 data_utils.py:450] Processing batch 174000\n",
            "I0809 02:49:54.758582 140415303137152 data_utils.py:450] Processing batch 174500\n",
            "I0809 02:50:07.011811 140415303137152 data_utils.py:450] Processing batch 175000\n",
            "I0809 02:50:19.530280 140415303137152 data_utils.py:450] Processing batch 175500\n",
            "I0809 02:50:32.068498 140415303137152 data_utils.py:450] Processing batch 176000\n",
            "I0809 02:50:44.629138 140415303137152 data_utils.py:450] Processing batch 176500\n",
            "I0809 02:50:57.126390 140415303137152 data_utils.py:450] Processing batch 177000\n",
            "I0809 02:51:09.536149 140415303137152 data_utils.py:450] Processing batch 177500\n",
            "I0809 02:51:21.909473 140415303137152 data_utils.py:450] Processing batch 178000\n",
            "I0809 02:51:33.961805 140415303137152 data_utils.py:450] Processing batch 178500\n",
            "I0809 02:51:46.393647 140415303137152 data_utils.py:450] Processing batch 179000\n",
            "I0809 02:51:58.659518 140415303137152 data_utils.py:450] Processing batch 179500\n",
            "I0809 02:52:10.854534 140415303137152 data_utils.py:450] Processing batch 180000\n",
            "I0809 02:52:22.908137 140415303137152 data_utils.py:450] Processing batch 180500\n",
            "I0809 02:52:35.215723 140415303137152 data_utils.py:450] Processing batch 181000\n",
            "I0809 02:52:47.232615 140415303137152 data_utils.py:450] Processing batch 181500\n",
            "I0809 02:52:59.311663 140415303137152 data_utils.py:450] Processing batch 182000\n",
            "I0809 02:53:11.317420 140415303137152 data_utils.py:450] Processing batch 182500\n",
            "I0809 02:53:23.469034 140415303137152 data_utils.py:450] Processing batch 183000\n",
            "I0809 02:53:35.807128 140415303137152 data_utils.py:450] Processing batch 183500\n",
            "I0809 02:53:48.055244 140415303137152 data_utils.py:450] Processing batch 184000\n",
            "I0809 02:54:00.274137 140415303137152 data_utils.py:450] Processing batch 184500\n",
            "I0809 02:54:12.231987 140415303137152 data_utils.py:450] Processing batch 185000\n",
            "I0809 02:54:24.498737 140415303137152 data_utils.py:450] Processing batch 185500\n",
            "I0809 02:54:36.692644 140415303137152 data_utils.py:450] Processing batch 186000\n",
            "I0809 02:54:48.741799 140415303137152 data_utils.py:450] Processing batch 186500\n",
            "I0809 02:55:00.922884 140415303137152 data_utils.py:450] Processing batch 187000\n",
            "I0809 02:55:12.997810 140415303137152 data_utils.py:450] Processing batch 187500\n",
            "I0809 02:55:25.275927 140415303137152 data_utils.py:450] Processing batch 188000\n",
            "I0809 02:55:37.520034 140415303137152 data_utils.py:450] Processing batch 188500\n",
            "I0809 02:55:49.944828 140415303137152 data_utils.py:450] Processing batch 189000\n",
            "I0809 02:56:02.312630 140415303137152 data_utils.py:450] Processing batch 189500\n",
            "I0809 02:56:14.874767 140415303137152 data_utils.py:450] Processing batch 190000\n",
            "I0809 02:56:27.377034 140415303137152 data_utils.py:450] Processing batch 190500\n",
            "I0809 02:56:39.890330 140415303137152 data_utils.py:450] Processing batch 191000\n",
            "I0809 02:56:52.121627 140415303137152 data_utils.py:450] Processing batch 191500\n",
            "I0809 02:57:04.557353 140415303137152 data_utils.py:450] Processing batch 192000\n",
            "I0809 02:57:16.855039 140415303137152 data_utils.py:450] Processing batch 192500\n",
            "I0809 02:57:29.060606 140415303137152 data_utils.py:450] Processing batch 193000\n",
            "I0809 02:57:41.432900 140415303137152 data_utils.py:450] Processing batch 193500\n",
            "I0809 02:57:53.864944 140415303137152 data_utils.py:450] Processing batch 194000\n",
            "I0809 02:58:06.212925 140415303137152 data_utils.py:450] Processing batch 194500\n",
            "I0809 02:58:18.534044 140415303137152 data_utils.py:450] Processing batch 195000\n",
            "I0809 02:58:30.921879 140415303137152 data_utils.py:450] Processing batch 195500\n",
            "I0809 02:58:43.324425 140415303137152 data_utils.py:450] Processing batch 196000\n",
            "I0809 02:58:55.875372 140415303137152 data_utils.py:450] Processing batch 196500\n",
            "I0809 02:59:08.183578 140415303137152 data_utils.py:450] Processing batch 197000\n",
            "I0809 02:59:20.000898 140415303137152 data_utils.py:450] Processing batch 197500\n",
            "I0809 02:59:32.108026 140415303137152 data_utils.py:450] Processing batch 198000\n",
            "I0809 02:59:43.988554 140415303137152 data_utils.py:450] Processing batch 198500\n",
            "I0809 02:59:55.910176 140415303137152 data_utils.py:450] Processing batch 199000\n",
            "I0809 03:00:07.925692 140415303137152 data_utils.py:450] Processing batch 199500\n",
            "I0809 03:00:19.525658 140415303137152 data_utils.py:450] Processing batch 200000\n",
            "I0809 03:00:31.278465 140415303137152 data_utils.py:450] Processing batch 200500\n",
            "I0809 03:00:43.229711 140415303137152 data_utils.py:450] Processing batch 201000\n",
            "I0809 03:00:55.380207 140415303137152 data_utils.py:450] Processing batch 201500\n",
            "I0809 03:01:07.394466 140415303137152 data_utils.py:450] Processing batch 202000\n",
            "I0809 03:01:19.937109 140415303137152 data_utils.py:450] Processing batch 202500\n",
            "I0809 03:01:32.260376 140415303137152 data_utils.py:450] Processing batch 203000\n",
            "I0809 03:01:44.400131 140415303137152 data_utils.py:450] Processing batch 203500\n",
            "I0809 03:01:56.695198 140415303137152 data_utils.py:450] Processing batch 204000\n",
            "I0809 03:02:09.026705 140415303137152 data_utils.py:450] Processing batch 204500\n",
            "I0809 03:02:21.266372 140415303137152 data_utils.py:450] Processing batch 205000\n",
            "I0809 03:02:33.525629 140415303137152 data_utils.py:450] Processing batch 205500\n",
            "I0809 03:02:45.964500 140415303137152 data_utils.py:450] Processing batch 206000\n",
            "I0809 03:02:58.345365 140415303137152 data_utils.py:450] Processing batch 206500\n",
            "I0809 03:03:10.653647 140415303137152 data_utils.py:450] Processing batch 207000\n",
            "I0809 03:03:22.401116 140415303137152 data_utils.py:450] Processing batch 207500\n",
            "I0809 03:03:34.349426 140415303137152 data_utils.py:450] Processing batch 208000\n",
            "I0809 03:03:46.516872 140415303137152 data_utils.py:450] Processing batch 208500\n",
            "I0809 03:03:58.378044 140415303137152 data_utils.py:450] Processing batch 209000\n",
            "I0809 03:04:10.771646 140415303137152 data_utils.py:450] Processing batch 209500\n",
            "I0809 03:04:23.092502 140415303137152 data_utils.py:450] Processing batch 210000\n",
            "I0809 03:04:35.615373 140415303137152 data_utils.py:450] Processing batch 210500\n",
            "I0809 03:04:47.813683 140415303137152 data_utils.py:450] Processing batch 211000\n",
            "I0809 03:05:00.159541 140415303137152 data_utils.py:450] Processing batch 211500\n",
            "I0809 03:05:12.301754 140415303137152 data_utils.py:450] Processing batch 212000\n",
            "I0809 03:05:24.642975 140415303137152 data_utils.py:450] Processing batch 212500\n",
            "I0809 03:05:36.982813 140415303137152 data_utils.py:450] Processing batch 213000\n",
            "I0809 03:05:49.254039 140415303137152 data_utils.py:450] Processing batch 213500\n",
            "I0809 03:06:01.472812 140415303137152 data_utils.py:450] Processing batch 214000\n",
            "I0809 03:06:13.645167 140415303137152 data_utils.py:450] Processing batch 214500\n",
            "I0809 03:06:25.980465 140415303137152 data_utils.py:450] Processing batch 215000\n",
            "I0809 03:06:38.480288 140415303137152 data_utils.py:450] Processing batch 215500\n",
            "I0809 03:06:51.087636 140415303137152 data_utils.py:450] Processing batch 216000\n",
            "I0809 03:07:03.085932 140415303137152 data_utils.py:450] Processing batch 216500\n",
            "I0809 03:07:15.358026 140415303137152 data_utils.py:450] Processing batch 217000\n",
            "I0809 03:07:27.734169 140415303137152 data_utils.py:450] Processing batch 217500\n",
            "I0809 03:07:40.178845 140415303137152 data_utils.py:450] Processing batch 218000\n",
            "I0809 03:07:52.487571 140415303137152 data_utils.py:450] Processing batch 218500\n",
            "I0809 03:08:04.761102 140415303137152 data_utils.py:450] Processing batch 219000\n",
            "I0809 03:08:17.216126 140415303137152 data_utils.py:450] Processing batch 219500\n",
            "I0809 03:08:29.766923 140415303137152 data_utils.py:450] Processing batch 220000\n",
            "I0809 03:08:41.999222 140415303137152 data_utils.py:450] Processing batch 220500\n",
            "I0809 03:08:54.497639 140415303137152 data_utils.py:450] Processing batch 221000\n",
            "I0809 03:09:06.799942 140415303137152 data_utils.py:450] Processing batch 221500\n",
            "I0809 03:09:19.094236 140415303137152 data_utils.py:450] Processing batch 222000\n",
            "I0809 03:09:31.443907 140415303137152 data_utils.py:450] Processing batch 222500\n",
            "I0809 03:09:43.937813 140415303137152 data_utils.py:450] Processing batch 223000\n",
            "I0809 03:09:56.258742 140415303137152 data_utils.py:450] Processing batch 223500\n",
            "I0809 03:10:08.515077 140415303137152 data_utils.py:450] Processing batch 224000\n",
            "I0809 03:10:20.780954 140415303137152 data_utils.py:450] Processing batch 224500\n",
            "I0809 03:10:33.004793 140415303137152 data_utils.py:450] Processing batch 225000\n",
            "I0809 03:10:45.220348 140415303137152 data_utils.py:450] Processing batch 225500\n",
            "I0809 03:10:57.180921 140415303137152 data_utils.py:450] Processing batch 226000\n",
            "I0809 03:11:09.499484 140415303137152 data_utils.py:450] Processing batch 226500\n",
            "I0809 03:11:21.571231 140415303137152 data_utils.py:450] Processing batch 227000\n",
            "I0809 03:11:34.068872 140415303137152 data_utils.py:450] Processing batch 227500\n",
            "I0809 03:11:46.184636 140415303137152 data_utils.py:450] Processing batch 228000\n",
            "I0809 03:11:58.354518 140415303137152 data_utils.py:450] Processing batch 228500\n",
            "I0809 03:12:10.454375 140415303137152 data_utils.py:450] Processing batch 229000\n",
            "I0809 03:12:22.698041 140415303137152 data_utils.py:450] Processing batch 229500\n",
            "I0809 03:12:34.696386 140415303137152 data_utils.py:450] Processing batch 230000\n",
            "I0809 03:12:47.049683 140415303137152 data_utils.py:450] Processing batch 230500\n",
            "I0809 03:12:59.273954 140415303137152 data_utils.py:450] Processing batch 231000\n",
            "I0809 03:13:11.610986 140415303137152 data_utils.py:450] Processing batch 231500\n",
            "I0809 03:13:23.891416 140415303137152 data_utils.py:450] Processing batch 232000\n",
            "I0809 03:13:36.137034 140415303137152 data_utils.py:450] Processing batch 232500\n",
            "I0809 03:13:48.432977 140415303137152 data_utils.py:450] Processing batch 233000\n",
            "I0809 03:14:00.649210 140415303137152 data_utils.py:450] Processing batch 233500\n",
            "I0809 03:14:12.781447 140415303137152 data_utils.py:450] Processing batch 234000\n",
            "I0809 03:14:24.917675 140415303137152 data_utils.py:450] Processing batch 234500\n",
            "I0809 03:14:37.031925 140415303137152 data_utils.py:450] Processing batch 235000\n",
            "I0809 03:14:49.121073 140415303137152 data_utils.py:450] Processing batch 235500\n",
            "I0809 03:15:01.429158 140415303137152 data_utils.py:450] Processing batch 236000\n",
            "I0809 03:15:13.828691 140415303137152 data_utils.py:450] Processing batch 236500\n",
            "I0809 03:15:26.298418 140415303137152 data_utils.py:450] Processing batch 237000\n",
            "I0809 03:15:38.460368 140415303137152 data_utils.py:450] Processing batch 237500\n",
            "I0809 03:15:50.859852 140415303137152 data_utils.py:450] Processing batch 238000\n",
            "I0809 03:16:03.411824 140415303137152 data_utils.py:450] Processing batch 238500\n",
            "I0809 03:16:15.684169 140415303137152 data_utils.py:450] Processing batch 239000\n",
            "I0809 03:16:27.977598 140415303137152 data_utils.py:450] Processing batch 239500\n",
            "I0809 03:16:40.264994 140415303137152 data_utils.py:450] Processing batch 240000\n",
            "I0809 03:16:52.595267 140415303137152 data_utils.py:450] Processing batch 240500\n",
            "I0809 03:17:04.916653 140415303137152 data_utils.py:450] Processing batch 241000\n",
            "I0809 03:17:17.356088 140415303137152 data_utils.py:450] Processing batch 241500\n",
            "I0809 03:17:29.923608 140415303137152 data_utils.py:450] Processing batch 242000\n",
            "I0809 03:17:42.265112 140415303137152 data_utils.py:450] Processing batch 242500\n",
            "I0809 03:17:54.671466 140415303137152 data_utils.py:450] Processing batch 243000\n",
            "I0809 03:18:06.763311 140415303137152 data_utils.py:450] Processing batch 243500\n",
            "I0809 03:18:19.059965 140415303137152 data_utils.py:450] Processing batch 244000\n",
            "I0809 03:18:31.423632 140415303137152 data_utils.py:450] Processing batch 244500\n",
            "I0809 03:18:43.541995 140415303137152 data_utils.py:450] Processing batch 245000\n",
            "I0809 03:18:55.723725 140415303137152 data_utils.py:450] Processing batch 245500\n",
            "I0809 03:19:08.094464 140415303137152 data_utils.py:450] Processing batch 246000\n",
            "I0809 03:19:20.234839 140415303137152 data_utils.py:450] Processing batch 246500\n",
            "I0809 03:19:32.477201 140415303137152 data_utils.py:450] Processing batch 247000\n",
            "I0809 03:19:44.728710 140415303137152 data_utils.py:450] Processing batch 247500\n",
            "I0809 03:19:57.082417 140415303137152 data_utils.py:450] Processing batch 248000\n",
            "I0809 03:20:09.575130 140415303137152 data_utils.py:450] Processing batch 248500\n",
            "I0809 03:20:21.947656 140415303137152 data_utils.py:450] Processing batch 249000\n",
            "I0809 03:20:34.329369 140415303137152 data_utils.py:450] Processing batch 249500\n",
            "I0809 03:20:46.666388 140415303137152 data_utils.py:450] Processing batch 250000\n",
            "I0809 03:20:59.110998 140415303137152 data_utils.py:450] Processing batch 250500\n",
            "I0809 03:21:11.504909 140415303137152 data_utils.py:450] Processing batch 251000\n",
            "I0809 03:21:24.083581 140415303137152 data_utils.py:450] Processing batch 251500\n",
            "I0809 03:21:36.350304 140415303137152 data_utils.py:450] Processing batch 252000\n",
            "I0809 03:21:48.641638 140415303137152 data_utils.py:450] Processing batch 252500\n",
            "I0809 03:22:01.011106 140415303137152 data_utils.py:450] Processing batch 253000\n",
            "I0809 03:22:13.070530 140415303137152 data_utils.py:450] Processing batch 253500\n",
            "I0809 03:22:25.359892 140415303137152 data_utils.py:450] Processing batch 254000\n",
            "I0809 03:22:37.624001 140415303137152 data_utils.py:450] Processing batch 254500\n",
            "I0809 03:22:49.846433 140415303137152 data_utils.py:450] Processing batch 255000\n",
            "I0809 03:23:02.122990 140415303137152 data_utils.py:450] Processing batch 255500\n",
            "I0809 03:23:14.667595 140415303137152 data_utils.py:450] Processing batch 256000\n",
            "I0809 03:23:27.427014 140415303137152 data_utils.py:450] Processing batch 256500\n",
            "I0809 03:23:39.422687 140415303137152 data_utils.py:450] Processing batch 257000\n",
            "I0809 03:23:51.534283 140415303137152 data_utils.py:450] Processing batch 257500\n",
            "I0809 03:24:03.980146 140415303137152 data_utils.py:450] Processing batch 258000\n",
            "I0809 03:24:16.636897 140415303137152 data_utils.py:450] Processing batch 258500\n",
            "I0809 03:24:29.097751 140415303137152 data_utils.py:450] Processing batch 259000\n",
            "I0809 03:24:41.428348 140415303137152 data_utils.py:450] Processing batch 259500\n",
            "I0809 03:24:53.691091 140415303137152 data_utils.py:450] Processing batch 260000\n",
            "I0809 03:25:06.056576 140415303137152 data_utils.py:450] Processing batch 260500\n",
            "I0809 03:25:18.169916 140415303137152 data_utils.py:450] Processing batch 261000\n",
            "I0809 03:25:30.185722 140415303137152 data_utils.py:450] Processing batch 261500\n",
            "I0809 03:25:42.624872 140415303137152 data_utils.py:450] Processing batch 262000\n",
            "I0809 03:25:44.124636 140415303137152 data_utils.py:523] Done writing tf_info/tfrecords/train-0-0.bsz-8.seqlen-128.reuse-64.uncased.uni.alpha-6.beta-1.fnp-21.tfrecords. Num of batches: 262065\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "avf0NrT-iOhB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cp -r /content/drive/data/tf_info /content/xlnet_train/xlnet"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YYnTikARy1gl",
        "colab_type": "code",
        "outputId": "9e4a3c2d-fce2-493b-8414-a46b6e9b3363",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "comond = \"python train_gpu.py \\\n",
        "  --record_info_dir=tf_info/tfrecords \\\n",
        "  --train_batch_size=8 \\\n",
        "  --num_core_per_host=1 \\\n",
        "  --seq_len=128 \\\n",
        "  --reuse_len=64 \\\n",
        "  --mem_len=96 \\\n",
        "  --perm_size=64 \\\n",
        "  --n_layer=6 \\\n",
        "  --d_model=768 \\\n",
        "  --d_embed=768 \\\n",
        "  --n_head=6 \\\n",
        "  --d_head=64 \\\n",
        "  --d_inner=3072 \\\n",
        "  --untie_r=true \\\n",
        "  --mask_alpha=6 \\\n",
        "  --mask_beta=1 \\\n",
        "  --num_predict=21 \\\n",
        "  --model_dir=ch_model \\\n",
        "  --uncased=true \\\n",
        "  --bi_data=False \\\n",
        "  --save_steps=10000 \\\n",
        "  --learning_rate=0.01 \\\n",
        "  --train_steps=50000 \"\n",
        "!{comond}"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING: Logging before flag parsing goes to stderr.\n",
            "W0812 01:30:25.032186 140038008952704 deprecation_wrapper.py:119] From /content/xlnet_train/xlnet/model_utils.py:295: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "W0812 01:30:25.043943 140038008952704 deprecation_wrapper.py:119] From train_gpu.py:328: The name tf.app.run is deprecated. Please use tf.compat.v1.app.run instead.\n",
            "\n",
            "W0812 01:30:25.044651 140038008952704 deprecation_wrapper.py:119] From train_gpu.py:315: The name tf.logging.set_verbosity is deprecated. Please use tf.compat.v1.logging.set_verbosity instead.\n",
            "\n",
            "W0812 01:30:25.044798 140038008952704 deprecation_wrapper.py:119] From train_gpu.py:315: The name tf.logging.INFO is deprecated. Please use tf.compat.v1.logging.INFO instead.\n",
            "\n",
            "W0812 01:30:25.044926 140038008952704 deprecation_wrapper.py:119] From train_gpu.py:319: The name tf.logging.info is deprecated. Please use tf.compat.v1.logging.info instead.\n",
            "\n",
            "I0812 01:30:25.045015 140038008952704 train_gpu.py:319] n_token 32000\n",
            "W0812 01:30:25.045120 140038008952704 deprecation_wrapper.py:119] From train_gpu.py:321: The name tf.gfile.Exists is deprecated. Please use tf.io.gfile.exists instead.\n",
            "\n",
            "W0812 01:30:25.045319 140038008952704 deprecation_wrapper.py:119] From train_gpu.py:322: The name tf.gfile.MakeDirs is deprecated. Please use tf.io.gfile.makedirs instead.\n",
            "\n",
            "I0812 01:30:25.045564 140038008952704 data_utils.py:795] Use the following tfrecord dirs: ['tf_info/tfrecords']\n",
            "I0812 01:30:25.045696 140038008952704 data_utils.py:799] [0] Record glob: tf_info/tfrecords/record_info-train-*.bsz-8.seqlen-128.reuse-64.uncased.uni.alpha-6.beta-1.fnp-21.json\n",
            "W0812 01:30:25.045801 140038008952704 deprecation_wrapper.py:119] From /content/xlnet_train/xlnet/data_utils.py:801: The name tf.gfile.Glob is deprecated. Please use tf.io.gfile.glob instead.\n",
            "\n",
            "I0812 01:30:25.046705 140038008952704 data_utils.py:803] [0] Num of record info path: 1\n",
            "W0812 01:30:25.046865 140038008952704 deprecation_wrapper.py:119] From /content/xlnet_train/xlnet/data_utils.py:816: The name tf.gfile.Open is deprecated. Please use tf.io.gfile.GFile instead.\n",
            "\n",
            "I0812 01:30:25.047661 140038008952704 data_utils.py:836] [Dir 0] Number of chosen batches: 262065\n",
            "I0812 01:30:25.047773 140038008952704 data_utils.py:838] [Dir 0] Number of chosen files: 1\n",
            "I0812 01:30:25.047854 140038008952704 data_utils.py:839] ['tf_info/tfrecords/train-0-0.bsz-8.seqlen-128.reuse-64.uncased.uni.alpha-6.beta-1.fnp-21.tfrecords']\n",
            "I0812 01:30:25.047931 140038008952704 data_utils.py:846] Total number of batches: 262065\n",
            "I0812 01:30:25.048690 140038008952704 data_utils.py:848] Total number of files: 1\n",
            "I0812 01:30:25.048777 140038008952704 data_utils.py:849] ['tf_info/tfrecords/train-0-0.bsz-8.seqlen-128.reuse-64.uncased.uni.alpha-6.beta-1.fnp-21.tfrecords']\n",
            "I0812 01:30:25.048862 140038008952704 train_gpu.py:204] num of batches 262065\n",
            "I0812 01:30:25.048951 140038008952704 data_utils.py:555] Host 0 handles 1 files\n",
            "W0812 01:30:25.086754 140038008952704 deprecation_wrapper.py:119] From /content/xlnet_train/xlnet/data_utils.py:661: The name tf.FixedLenFeature is deprecated. Please use tf.io.FixedLenFeature instead.\n",
            "\n",
            "W0812 01:30:25.087041 140038008952704 deprecation_wrapper.py:119] From /content/xlnet_train/xlnet/data_utils.py:669: The name tf.parse_single_example is deprecated. Please use tf.io.parse_single_example instead.\n",
            "\n",
            "W0812 01:30:25.108673 140038008952704 deprecation_wrapper.py:119] From /content/xlnet_train/xlnet/data_utils.py:597: The name tf.random_shuffle is deprecated. Please use tf.random.shuffle instead.\n",
            "\n",
            "W0812 01:30:25.119826 140038008952704 deprecation.py:323] From /content/xlnet_train/xlnet/data_utils.py:614: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "I0812 01:30:25.297124 140038008952704 data_utils.py:744] label: Tensor(\"Cast_6:0\", shape=(1,), dtype=int32)\n",
            "I0812 01:30:25.297466 140038008952704 data_utils.py:744] seg_id: Tensor(\"Cast_7:0\", shape=(128,), dtype=int32)\n",
            "I0812 01:30:25.297645 140038008952704 data_utils.py:744] target_mapping: Tensor(\"Reshape_4:0\", shape=(21, 128), dtype=float32)\n",
            "I0812 01:30:25.297800 140038008952704 data_utils.py:744] target: Tensor(\"Cast_8:0\", shape=(21,), dtype=int32)\n",
            "I0812 01:30:25.297937 140038008952704 data_utils.py:744] target_mask: Tensor(\"Reshape_6:0\", shape=(21,), dtype=float32)\n",
            "I0812 01:30:25.298071 140038008952704 data_utils.py:744] perm_mask: Tensor(\"Reshape_7:0\", shape=(128, 128), dtype=float32)\n",
            "I0812 01:30:25.298212 140038008952704 data_utils.py:744] input_k: Tensor(\"Cast_9:0\", shape=(128,), dtype=int32)\n",
            "I0812 01:30:25.298343 140038008952704 data_utils.py:744] input_q: Tensor(\"Reshape_9:0\", shape=(128,), dtype=float32)\n",
            "W0812 01:30:25.334625 140038008952704 deprecation.py:323] From train_gpu.py:214: DatasetV1.make_one_shot_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_one_shot_iterator(dataset)`.\n",
            "W0812 01:30:25.353621 140038008952704 deprecation_wrapper.py:119] From train_gpu.py:231: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.\n",
            "\n",
            "W0812 01:30:25.353832 140038008952704 deprecation_wrapper.py:119] From train_gpu.py:231: The name tf.get_variable_scope is deprecated. Please use tf.compat.v1.get_variable_scope instead.\n",
            "\n",
            "I0812 01:30:25.369562 140038008952704 modeling.py:453] memory input [<tf.Tensor 'Placeholder:0' shape=(96, 8, 768) dtype=float32>, <tf.Tensor 'Placeholder_1:0' shape=(96, 8, 768) dtype=float32>, <tf.Tensor 'Placeholder_2:0' shape=(96, 8, 768) dtype=float32>, <tf.Tensor 'Placeholder_3:0' shape=(96, 8, 768) dtype=float32>, <tf.Tensor 'Placeholder_4:0' shape=(96, 8, 768) dtype=float32>, <tf.Tensor 'Placeholder_5:0' shape=(96, 8, 768) dtype=float32>]\n",
            "I0812 01:30:25.369729 140038008952704 modeling.py:455] Use float type <dtype: 'float32'>\n",
            "W0812 01:30:25.448887 140038008952704 deprecation.py:506] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
            "W0812 01:30:25.464685 140038008952704 deprecation.py:323] From /content/xlnet_train/xlnet/modeling.py:535: dropout (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use keras.layers.dropout instead.\n",
            "W0812 01:30:28.194599 140038008952704 lazy_loader.py:50] \n",
            "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
            "For more information, please see:\n",
            "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
            "  * https://github.com/tensorflow/addons\n",
            "  * https://github.com/tensorflow/io (for I/O related ops)\n",
            "If you depend on functionality not listed there, please file an issue.\n",
            "\n",
            "W0812 01:30:28.380548 140038008952704 deprecation.py:323] From /content/xlnet_train/xlnet/modeling.py:67: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use keras.layers.dense instead.\n",
            "I0812 01:30:31.717364 140038008952704 train_gpu.py:142] #params: 61820672\n",
            "W0812 01:30:37.051387 140038008952704 deprecation_wrapper.py:119] From /content/xlnet_train/xlnet/model_utils.py:96: The name tf.train.get_or_create_global_step is deprecated. Please use tf.compat.v1.train.get_or_create_global_step instead.\n",
            "\n",
            "W0812 01:30:37.056097 140038008952704 deprecation_wrapper.py:119] From /content/xlnet_train/xlnet/model_utils.py:108: The name tf.train.polynomial_decay is deprecated. Please use tf.compat.v1.train.polynomial_decay instead.\n",
            "\n",
            "W0812 01:30:37.063020 140038008952704 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/optimizer_v2/learning_rate_schedule.py:409: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Deprecated in favor of operator or tf.math.divide.\n",
            "W0812 01:30:37.070928 140038008952704 deprecation_wrapper.py:119] From /content/xlnet_train/xlnet/model_utils.py:131: The name tf.train.AdamOptimizer is deprecated. Please use tf.compat.v1.train.AdamOptimizer instead.\n",
            "\n",
            "W0812 01:30:38.479569 140038008952704 deprecation_wrapper.py:119] From train_gpu.py:259: The name tf.train.get_global_step is deprecated. Please use tf.compat.v1.train.get_global_step instead.\n",
            "\n",
            "2019-08-12 01:30:38.990326: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\n",
            "2019-08-12 01:30:39.015315: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcuda.so.1\n",
            "2019-08-12 01:30:39.162170: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2019-08-12 01:30:39.162840: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x1468bc0 executing computations on platform CUDA. Devices:\n",
            "2019-08-12 01:30:39.162885: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): Tesla K80, Compute Capability 3.7\n",
            "2019-08-12 01:30:39.168588: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2300000000 Hz\n",
            "2019-08-12 01:30:39.168923: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x1469100 executing computations on platform Host. Devices:\n",
            "2019-08-12 01:30:39.168953: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>\n",
            "2019-08-12 01:30:39.169346: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2019-08-12 01:30:39.169762: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: \n",
            "name: Tesla K80 major: 3 minor: 7 memoryClockRate(GHz): 0.8235\n",
            "pciBusID: 0000:00:04.0\n",
            "2019-08-12 01:30:39.176377: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0\n",
            "2019-08-12 01:30:39.379354: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0\n",
            "2019-08-12 01:30:39.462435: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcufft.so.10.0\n",
            "2019-08-12 01:30:39.485772: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcurand.so.10.0\n",
            "2019-08-12 01:30:39.700693: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusolver.so.10.0\n",
            "2019-08-12 01:30:39.812313: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusparse.so.10.0\n",
            "2019-08-12 01:30:40.210651: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7\n",
            "2019-08-12 01:30:40.211013: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2019-08-12 01:30:40.211560: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2019-08-12 01:30:40.211941: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0\n",
            "2019-08-12 01:30:40.212206: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0\n",
            "2019-08-12 01:30:40.213838: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1181] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2019-08-12 01:30:40.213877: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1187]      0 \n",
            "2019-08-12 01:30:40.213897: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1200] 0:   N \n",
            "2019-08-12 01:30:40.214505: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2019-08-12 01:30:40.215007: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2019-08-12 01:30:40.215413: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1326] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10802 MB memory) -> physical GPU (device: 0, name: Tesla K80, pci bus id: 0000:00:04.0, compute capability: 3.7)\n",
            "2019-08-12 01:30:49.646579: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0\n",
            "I0812 01:36:42.165961 140038008952704 train_gpu.py:300] [1000] | gnorm 2.13 lr 0.009800 | loss 6.85 | pplx  940.12, bpc  9.8767\n",
            "I0812 01:42:34.459838 140038008952704 train_gpu.py:300] [2000] | gnorm 1.28 lr 0.009600 | loss 6.58 | pplx  719.57, bpc  9.4910\n",
            "I0812 01:48:25.451205 140038008952704 train_gpu.py:300] [3000] | gnorm 1.28 lr 0.009401 | loss 6.54 | pplx  691.86, bpc  9.4343\n",
            "I0812 01:54:15.627550 140038008952704 train_gpu.py:300] [4000] | gnorm 1.16 lr 0.009201 | loss 6.54 | pplx  693.73, bpc  9.4382\n",
            "I0812 02:00:05.876506 140038008952704 train_gpu.py:300] [5000] | gnorm 1.43 lr 0.009001 | loss 6.59 | pplx  724.39, bpc  9.5006\n",
            "I0812 02:05:56.372991 140038008952704 train_gpu.py:300] [6000] | gnorm 1.27 lr 0.008801 | loss 6.58 | pplx  720.68, bpc  9.4932\n",
            "I0812 02:11:46.966724 140038008952704 train_gpu.py:300] [7000] | gnorm 1.52 lr 0.008601 | loss 6.58 | pplx  718.60, bpc  9.4891\n",
            "I0812 02:17:38.403819 140038008952704 train_gpu.py:300] [8000] | gnorm 1.56 lr 0.008402 | loss 6.56 | pplx  705.86, bpc  9.4632\n",
            "I0812 02:23:33.839198 140038008952704 train_gpu.py:300] [9000] | gnorm 1.35 lr 0.008202 | loss 6.58 | pplx  718.03, bpc  9.4879\n",
            "I0812 02:29:27.171602 140038008952704 train_gpu.py:300] [10000] | gnorm 2.09 lr 0.008002 | loss 6.57 | pplx  710.97, bpc  9.4736\n",
            "I0812 02:29:30.359758 140038008952704 train_gpu.py:306] Model saved in path: ch_model/model.ckpt\n",
            "I0812 02:35:25.372186 140038008952704 train_gpu.py:300] [11000] | gnorm 1.58 lr 0.007802 | loss 6.57 | pplx  710.96, bpc  9.4736\n",
            "I0812 02:41:17.338198 140038008952704 train_gpu.py:300] [12000] | gnorm 1.34 lr 0.007602 | loss 6.54 | pplx  691.35, bpc  9.4333\n",
            "I0812 02:47:07.395107 140038008952704 train_gpu.py:300] [13000] | gnorm 2.61 lr 0.007403 | loss 6.53 | pplx  683.30, bpc  9.4164\n",
            "I0812 02:52:57.616920 140038008952704 train_gpu.py:300] [14000] | gnorm 1.84 lr 0.007203 | loss 6.57 | pplx  712.71, bpc  9.4772\n",
            "I0812 02:58:47.795105 140038008952704 train_gpu.py:300] [15000] | gnorm 1.61 lr 0.007003 | loss 6.59 | pplx  729.77, bpc  9.5113\n",
            "I0812 03:04:37.804424 140038008952704 train_gpu.py:300] [16000] | gnorm 1.49 lr 0.006803 | loss 6.57 | pplx  713.08, bpc  9.4779\n",
            "I0812 03:10:27.748636 140038008952704 train_gpu.py:300] [17000] | gnorm 1.66 lr 0.006603 | loss 6.55 | pplx  697.12, bpc  9.4453\n",
            "I0812 03:16:18.057111 140038008952704 train_gpu.py:300] [18000] | gnorm 1.73 lr 0.006404 | loss 6.54 | pplx  690.81, bpc  9.4322\n",
            "I0812 03:22:08.219034 140038008952704 train_gpu.py:300] [19000] | gnorm 1.63 lr 0.006204 | loss 6.54 | pplx  695.39, bpc  9.4417\n",
            "I0812 03:27:58.395336 140038008952704 train_gpu.py:300] [20000] | gnorm 1.55 lr 0.006004 | loss 6.54 | pplx  690.47, bpc  9.4314\n",
            "I0812 03:28:00.879499 140038008952704 train_gpu.py:306] Model saved in path: ch_model/model.ckpt\n",
            "I0812 03:33:50.996408 140038008952704 train_gpu.py:300] [21000] | gnorm 1.92 lr 0.005804 | loss 6.56 | pplx  703.89, bpc  9.4592\n",
            "I0812 03:39:43.171505 140038008952704 train_gpu.py:300] [22000] | gnorm 1.34 lr 0.005604 | loss 6.55 | pplx  696.46, bpc  9.4439\n",
            "I0812 03:45:32.864903 140038008952704 train_gpu.py:300] [23000] | gnorm 1.56 lr 0.005405 | loss 6.54 | pplx  694.60, bpc  9.4400\n",
            "I0812 03:51:22.778211 140038008952704 train_gpu.py:300] [24000] | gnorm 1.47 lr 0.005205 | loss 6.55 | pplx  696.56, bpc  9.4441\n",
            "I0812 03:57:12.617765 140038008952704 train_gpu.py:300] [25000] | gnorm 1.42 lr 0.005005 | loss 6.55 | pplx  696.64, bpc  9.4443\n",
            "I0812 04:03:04.662125 140038008952704 train_gpu.py:300] [26000] | gnorm 1.42 lr 0.004805 | loss 6.53 | pplx  687.03, bpc  9.4242\n",
            "I0812 04:09:00.299747 140038008952704 train_gpu.py:300] [27000] | gnorm 1.35 lr 0.004605 | loss 6.51 | pplx  672.46, bpc  9.3933\n",
            "I0812 04:14:55.227434 140038008952704 train_gpu.py:300] [28000] | gnorm 1.34 lr 0.004406 | loss 6.53 | pplx  686.29, bpc  9.4227\n",
            "I0812 04:20:50.226384 140038008952704 train_gpu.py:300] [29000] | gnorm 1.35 lr 0.004206 | loss 6.53 | pplx  684.04, bpc  9.4179\n",
            "I0812 04:26:45.291396 140038008952704 train_gpu.py:300] [30000] | gnorm 1.25 lr 0.004006 | loss 6.55 | pplx  700.33, bpc  9.4519\n",
            "I0812 04:26:47.881391 140038008952704 train_gpu.py:306] Model saved in path: ch_model/model.ckpt\n",
            "I0812 04:32:43.358422 140038008952704 train_gpu.py:300] [31000] | gnorm 1.84 lr 0.003806 | loss 6.56 | pplx  708.88, bpc  9.4694\n",
            "I0812 04:38:39.389351 140038008952704 train_gpu.py:300] [32000] | gnorm 1.83 lr 0.003606 | loss 6.57 | pplx  712.19, bpc  9.4761\n",
            "I0812 04:44:38.565137 140038008952704 train_gpu.py:300] [33000] | gnorm 1.35 lr 0.003407 | loss 6.56 | pplx  709.75, bpc  9.4712\n",
            "I0812 04:50:32.128660 140038008952704 train_gpu.py:300] [34000] | gnorm 1.30 lr 0.003207 | loss 6.52 | pplx  676.70, bpc  9.4024\n",
            "I0812 04:56:27.262784 140038008952704 train_gpu.py:300] [35000] | gnorm 1.62 lr 0.003007 | loss 6.51 | pplx  673.90, bpc  9.3964\n",
            "I0812 05:02:31.556894 140038008952704 train_gpu.py:300] [36000] | gnorm 1.51 lr 0.002807 | loss 6.53 | pplx  686.95, bpc  9.4241\n",
            "I0812 05:08:28.887793 140038008952704 train_gpu.py:300] [37000] | gnorm 1.37 lr 0.002607 | loss 6.51 | pplx  669.51, bpc  9.3870\n",
            "I0812 05:14:26.224264 140038008952704 train_gpu.py:300] [38000] | gnorm 1.23 lr 0.002408 | loss 6.51 | pplx  669.45, bpc  9.3868\n",
            "I0812 05:20:25.111752 140038008952704 train_gpu.py:300] [39000] | gnorm 1.19 lr 0.002208 | loss 6.50 | pplx  662.65, bpc  9.3721\n",
            "I0812 05:26:28.004841 140038008952704 train_gpu.py:300] [40000] | gnorm 1.20 lr 0.002008 | loss 6.51 | pplx  672.27, bpc  9.3929\n",
            "I0812 05:26:30.555449 140038008952704 train_gpu.py:306] Model saved in path: ch_model/model.ckpt\n",
            "I0812 05:32:32.908942 140038008952704 train_gpu.py:300] [41000] | gnorm 1.33 lr 0.001808 | loss 6.52 | pplx  675.87, bpc  9.4006\n",
            "I0812 05:38:32.493726 140038008952704 train_gpu.py:300] [42000] | gnorm 1.21 lr 0.001608 | loss 6.51 | pplx  673.75, bpc  9.3961\n",
            "I0812 05:44:31.990568 140038008952704 train_gpu.py:300] [43000] | gnorm 1.37 lr 0.001409 | loss 6.49 | pplx  661.46, bpc  9.3695\n",
            "I0812 05:50:28.450883 140038008952704 train_gpu.py:300] [44000] | gnorm 1.31 lr 0.001209 | loss 6.51 | pplx  673.48, bpc  9.3955\n",
            "I0812 05:56:24.928590 140038008952704 train_gpu.py:300] [45000] | gnorm 1.51 lr 0.001009 | loss 6.49 | pplx  660.98, bpc  9.3685\n",
            "I0812 06:02:21.187211 140038008952704 train_gpu.py:300] [46000] | gnorm 1.33 lr 0.000809 | loss 6.49 | pplx  658.92, bpc  9.3640\n",
            "I0812 06:08:17.199573 140038008952704 train_gpu.py:300] [47000] | gnorm 1.30 lr 0.000609 | loss 6.49 | pplx  660.51, bpc  9.3674\n",
            "I0812 06:14:14.754815 140038008952704 train_gpu.py:300] [48000] | gnorm 1.24 lr 0.000410 | loss 6.50 | pplx  661.98, bpc  9.3707\n",
            "I0812 06:20:10.371830 140038008952704 train_gpu.py:300] [49000] | gnorm 1.49 lr 0.000210 | loss 6.48 | pplx  653.89, bpc  9.3529\n",
            "I0812 06:26:05.615028 140038008952704 train_gpu.py:300] [50000] | gnorm 1.44 lr 0.000010 | loss 6.49 | pplx  658.78, bpc  9.3637\n",
            "I0812 06:26:08.137193 140038008952704 train_gpu.py:306] Model saved in path: ch_model/model.ckpt\n",
            "2019-08-12 06:26:08.536106: W tensorflow/core/kernels/data/cache_dataset_ops.cc:815] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rv_kRgsfmRco",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cp -r /content/xlnet_train/xlnet/ch_model /content/drive"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3UNFPVeiC1OM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "! cp -r /content/xlnet_train/xlnet/ch_model /content/drive/ch_model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aJlyvvmOwgmE",
        "colab_type": "code",
        "outputId": "703dcf36-e672-45b8-f21b-acdaced90365",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "#装opam,后装google-drive-ocamlfuse\n",
        "!apt-get install opam\n",
        "!opam init\n",
        "!opam update\n",
        "!opam install depext\n",
        "!opam depext google-drive-ocamlfuse\n",
        "!opam install google-drive-ocamlfuse\n",
        "#进行授权操作\n",
        "from google.colab import auth\n",
        "auth.authenticate_user()\n",
        "from oauth2client.client import GoogleCredentials\n",
        "creds = GoogleCredentials.get_application_default()\n",
        "import getpass\n",
        "!/root/.opam/system/bin/google-drive-ocamlfuse -headless -id={creds.client_id} -secret={creds.client_secret} < /dev/null 2>&1 | grep URL\n",
        "vcode = getpass.getpass()\n",
        "!echo {vcode} | /root/.opam/system/bin/google-drive-ocamlfuse -headless -id={creds.client_id} -secret={creds.client_secret}\n",
        "#!!!注意，里面的/root/.opam/system/bin/google-drive-ocamlfuse换成你自己的路径,一般来说你也会得到和我一样的结果\n",
        "# 指定Google Drive云端硬盘的根目录，名为drive\n",
        "!mkdir -p drive\n",
        "!/root/.opam/system/bin/google-drive-ocamlfuse drive"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "The following package was automatically installed and is no longer required:\n",
            "  libnvidia-common-410\n",
            "Use 'apt autoremove' to remove it.\n",
            "The following additional packages will be installed:\n",
            "  aspcud camlp4 clasp darcs file gringo ledit libcamlp4-ocaml-dev\n",
            "  libfindlib-ocaml libfindlib-ocaml-dev liblua5.3-0 libmagic-mgc libmagic1\n",
            "  mercurial mercurial-common ocaml ocaml-base ocaml-base-nox\n",
            "  ocaml-compiler-libs ocaml-findlib ocaml-interp ocaml-nox opam-docs\n",
            "Suggested packages:\n",
            "  kdiff3 | kdiff3-qt | kompare | meld | tkcvs | mgdiff qct python-mysqldb\n",
            "  python-openssl python-pygments ocaml-doc tuareg-mode | ocaml-mode\n",
            "The following NEW packages will be installed:\n",
            "  aspcud camlp4 clasp darcs file gringo ledit libcamlp4-ocaml-dev\n",
            "  libfindlib-ocaml libfindlib-ocaml-dev liblua5.3-0 libmagic-mgc libmagic1\n",
            "  mercurial mercurial-common ocaml ocaml-base ocaml-base-nox\n",
            "  ocaml-compiler-libs ocaml-findlib ocaml-interp ocaml-nox opam opam-docs\n",
            "0 upgraded, 24 newly installed, 0 to remove and 4 not upgraded.\n",
            "Need to get 84.9 MB of archives.\n",
            "After this operation, 465 MB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 libmagic-mgc amd64 1:5.32-2ubuntu0.2 [184 kB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 libmagic1 amd64 1:5.32-2ubuntu0.2 [68.5 kB]\n",
            "Get:3 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 file amd64 1:5.32-2ubuntu0.2 [22.1 kB]\n",
            "Get:4 http://archive.ubuntu.com/ubuntu bionic/universe amd64 ocaml-base-nox amd64 4.05.0-10ubuntu1 [544 kB]\n",
            "Get:5 http://archive.ubuntu.com/ubuntu bionic/universe amd64 ocaml-compiler-libs amd64 4.05.0-10ubuntu1 [18.9 MB]\n",
            "Get:6 http://archive.ubuntu.com/ubuntu bionic/universe amd64 ocaml-interp amd64 4.05.0-10ubuntu1 [3,466 kB]\n",
            "Get:7 http://archive.ubuntu.com/ubuntu bionic/universe amd64 ocaml-nox amd64 4.05.0-10ubuntu1 [27.5 MB]\n",
            "Get:8 http://archive.ubuntu.com/ubuntu bionic/universe amd64 libcamlp4-ocaml-dev amd64 4.05+1-2 [16.2 MB]\n",
            "Get:9 http://archive.ubuntu.com/ubuntu bionic/universe amd64 camlp4 amd64 4.05+1-2 [4,896 kB]\n",
            "Get:10 http://archive.ubuntu.com/ubuntu bionic/universe amd64 darcs amd64 2.12.5-1 [4,244 kB]\n",
            "Get:11 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 liblua5.3-0 amd64 5.3.3-1ubuntu0.18.04.1 [115 kB]\n",
            "Get:12 http://archive.ubuntu.com/ubuntu bionic/universe amd64 gringo amd64 5.2.2-5 [2,185 kB]\n",
            "Get:13 http://archive.ubuntu.com/ubuntu bionic/universe amd64 ledit all 2.03-6 [44.9 kB]\n",
            "Get:14 http://archive.ubuntu.com/ubuntu bionic/universe amd64 libfindlib-ocaml amd64 1.7.3-2 [160 kB]\n",
            "Get:15 http://archive.ubuntu.com/ubuntu bionic/universe amd64 libfindlib-ocaml-dev amd64 1.7.3-2 [141 kB]\n",
            "Get:16 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 mercurial-common all 4.5.3-1ubuntu2.1 [2,198 kB]\n",
            "Get:17 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 mercurial amd64 4.5.3-1ubuntu2.1 [189 kB]\n",
            "Get:18 http://archive.ubuntu.com/ubuntu bionic/universe amd64 ocaml-base amd64 4.05.0-10ubuntu1 [44.9 kB]\n",
            "Get:19 http://archive.ubuntu.com/ubuntu bionic/universe amd64 ocaml amd64 4.05.0-10ubuntu1 [45.6 kB]\n",
            "Get:20 http://archive.ubuntu.com/ubuntu bionic/universe amd64 ocaml-findlib amd64 1.7.3-2 [366 kB]\n",
            "Get:21 http://archive.ubuntu.com/ubuntu bionic/universe amd64 opam-docs all 1.2.2-6 [310 kB]\n",
            "Get:22 http://archive.ubuntu.com/ubuntu bionic/universe amd64 opam amd64 1.2.2-6 [2,277 kB]\n",
            "Get:23 http://archive.ubuntu.com/ubuntu bionic/universe amd64 clasp amd64 3.3.3-3 [621 kB]\n",
            "Get:24 http://archive.ubuntu.com/ubuntu bionic/universe amd64 aspcud amd64 1:1.9.4-1 [137 kB]\n",
            "Fetched 84.9 MB in 8s (10.1 MB/s)\n",
            "Selecting previously unselected package libmagic-mgc.\n",
            "(Reading database ... 131289 files and directories currently installed.)\n",
            "Preparing to unpack .../00-libmagic-mgc_1%3a5.32-2ubuntu0.2_amd64.deb ...\n",
            "Unpacking libmagic-mgc (1:5.32-2ubuntu0.2) ...\n",
            "Selecting previously unselected package libmagic1:amd64.\n",
            "Preparing to unpack .../01-libmagic1_1%3a5.32-2ubuntu0.2_amd64.deb ...\n",
            "Unpacking libmagic1:amd64 (1:5.32-2ubuntu0.2) ...\n",
            "Selecting previously unselected package file.\n",
            "Preparing to unpack .../02-file_1%3a5.32-2ubuntu0.2_amd64.deb ...\n",
            "Unpacking file (1:5.32-2ubuntu0.2) ...\n",
            "Selecting previously unselected package ocaml-base-nox.\n",
            "Preparing to unpack .../03-ocaml-base-nox_4.05.0-10ubuntu1_amd64.deb ...\n",
            "Unpacking ocaml-base-nox (4.05.0-10ubuntu1) ...\n",
            "Selecting previously unselected package ocaml-compiler-libs.\n",
            "Preparing to unpack .../04-ocaml-compiler-libs_4.05.0-10ubuntu1_amd64.deb ...\n",
            "Unpacking ocaml-compiler-libs (4.05.0-10ubuntu1) ...\n",
            "Selecting previously unselected package ocaml-interp.\n",
            "Preparing to unpack .../05-ocaml-interp_4.05.0-10ubuntu1_amd64.deb ...\n",
            "Unpacking ocaml-interp (4.05.0-10ubuntu1) ...\n",
            "Selecting previously unselected package ocaml-nox.\n",
            "Preparing to unpack .../06-ocaml-nox_4.05.0-10ubuntu1_amd64.deb ...\n",
            "Unpacking ocaml-nox (4.05.0-10ubuntu1) ...\n",
            "Selecting previously unselected package libcamlp4-ocaml-dev.\n",
            "Preparing to unpack .../07-libcamlp4-ocaml-dev_4.05+1-2_amd64.deb ...\n",
            "Unpacking libcamlp4-ocaml-dev (4.05+1-2) ...\n",
            "Selecting previously unselected package camlp4.\n",
            "Preparing to unpack .../08-camlp4_4.05+1-2_amd64.deb ...\n",
            "Unpacking camlp4 (4.05+1-2) ...\n",
            "Selecting previously unselected package darcs.\n",
            "Preparing to unpack .../09-darcs_2.12.5-1_amd64.deb ...\n",
            "Unpacking darcs (2.12.5-1) ...\n",
            "Selecting previously unselected package liblua5.3-0:amd64.\n",
            "Preparing to unpack .../10-liblua5.3-0_5.3.3-1ubuntu0.18.04.1_amd64.deb ...\n",
            "Unpacking liblua5.3-0:amd64 (5.3.3-1ubuntu0.18.04.1) ...\n",
            "Selecting previously unselected package gringo.\n",
            "Preparing to unpack .../11-gringo_5.2.2-5_amd64.deb ...\n",
            "Unpacking gringo (5.2.2-5) ...\n",
            "Selecting previously unselected package ledit.\n",
            "Preparing to unpack .../12-ledit_2.03-6_all.deb ...\n",
            "Unpacking ledit (2.03-6) ...\n",
            "Selecting previously unselected package libfindlib-ocaml.\n",
            "Preparing to unpack .../13-libfindlib-ocaml_1.7.3-2_amd64.deb ...\n",
            "Unpacking libfindlib-ocaml (1.7.3-2) ...\n",
            "Selecting previously unselected package libfindlib-ocaml-dev.\n",
            "Preparing to unpack .../14-libfindlib-ocaml-dev_1.7.3-2_amd64.deb ...\n",
            "Unpacking libfindlib-ocaml-dev (1.7.3-2) ...\n",
            "Selecting previously unselected package mercurial-common.\n",
            "Preparing to unpack .../15-mercurial-common_4.5.3-1ubuntu2.1_all.deb ...\n",
            "Unpacking mercurial-common (4.5.3-1ubuntu2.1) ...\n",
            "Selecting previously unselected package mercurial.\n",
            "Preparing to unpack .../16-mercurial_4.5.3-1ubuntu2.1_amd64.deb ...\n",
            "Unpacking mercurial (4.5.3-1ubuntu2.1) ...\n",
            "Selecting previously unselected package ocaml-base.\n",
            "Preparing to unpack .../17-ocaml-base_4.05.0-10ubuntu1_amd64.deb ...\n",
            "Unpacking ocaml-base (4.05.0-10ubuntu1) ...\n",
            "Selecting previously unselected package ocaml.\n",
            "Preparing to unpack .../18-ocaml_4.05.0-10ubuntu1_amd64.deb ...\n",
            "Unpacking ocaml (4.05.0-10ubuntu1) ...\n",
            "Selecting previously unselected package ocaml-findlib.\n",
            "Preparing to unpack .../19-ocaml-findlib_1.7.3-2_amd64.deb ...\n",
            "Unpacking ocaml-findlib (1.7.3-2) ...\n",
            "Selecting previously unselected package opam-docs.\n",
            "Preparing to unpack .../20-opam-docs_1.2.2-6_all.deb ...\n",
            "Unpacking opam-docs (1.2.2-6) ...\n",
            "Selecting previously unselected package opam.\n",
            "Preparing to unpack .../21-opam_1.2.2-6_amd64.deb ...\n",
            "Unpacking opam (1.2.2-6) ...\n",
            "Selecting previously unselected package clasp.\n",
            "Preparing to unpack .../22-clasp_3.3.3-3_amd64.deb ...\n",
            "Unpacking clasp (3.3.3-3) ...\n",
            "Selecting previously unselected package aspcud.\n",
            "Preparing to unpack .../23-aspcud_1%3a1.9.4-1_amd64.deb ...\n",
            "Unpacking aspcud (1:1.9.4-1) ...\n",
            "Setting up opam-docs (1.2.2-6) ...\n",
            "Setting up darcs (2.12.5-1) ...\n",
            "Processing triggers for mime-support (3.60ubuntu1) ...\n",
            "Setting up opam (1.2.2-6) ...\n",
            "Setting up ocaml-base-nox (4.05.0-10ubuntu1) ...\n",
            "Setting up clasp (3.3.3-3) ...\n",
            "Setting up libmagic-mgc (1:5.32-2ubuntu0.2) ...\n",
            "Setting up libmagic1:amd64 (1:5.32-2ubuntu0.2) ...\n",
            "Setting up mercurial-common (4.5.3-1ubuntu2.1) ...\n",
            "Setting up mercurial (4.5.3-1ubuntu2.1) ...\n",
            "\n",
            "Creating config file /etc/mercurial/hgrc.d/hgext.rc with new version\n",
            "Setting up ocaml-base (4.05.0-10ubuntu1) ...\n",
            "Processing triggers for libc-bin (2.27-3ubuntu1) ...\n",
            "Processing triggers for man-db (2.8.3-2ubuntu0.1) ...\n",
            "Setting up liblua5.3-0:amd64 (5.3.3-1ubuntu0.18.04.1) ...\n",
            "Setting up libfindlib-ocaml (1.7.3-2) ...\n",
            "Setting up ocaml-findlib (1.7.3-2) ...\n",
            "Setting up ledit (2.03-6) ...\n",
            "update-alternatives: using /usr/bin/ledit to provide /usr/bin/readline-editor (readline-editor) in auto mode\n",
            "Setting up gringo (5.2.2-5) ...\n",
            "Setting up file (1:5.32-2ubuntu0.2) ...\n",
            "Setting up aspcud (1:1.9.4-1) ...\n",
            "Setting up ocaml-compiler-libs (4.05.0-10ubuntu1) ...\n",
            "Setting up ocaml-interp (4.05.0-10ubuntu1) ...\n",
            "Setting up ocaml-nox (4.05.0-10ubuntu1) ...\n",
            "Setting up libcamlp4-ocaml-dev (4.05+1-2) ...\n",
            "Setting up ocaml (4.05.0-10ubuntu1) ...\n",
            "Setting up camlp4 (4.05+1-2) ...\n",
            "Setting up libfindlib-ocaml-dev (1.7.3-2) ...\n",
            "Processing triggers for libc-bin (2.27-3ubuntu1) ...\n",
            "\u001b[33m[WARNING]\u001b[m Running as root is not recommended\n",
            "Checking for available remotes: rsync and local, git, mercurial, darcs. Perfect!\n",
            "\u001b[33m[WARNING]\u001b[m Recommended dependencies -- most packages rely on these:\n",
            "            - \u001b[01mm4\u001b[m\n",
            "\n",
            "\n",
            "\u001b[36m=-=-\u001b[m \u001b[01mFetching repository information\u001b[m \u001b[36m=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=\u001b[m\n",
            "\u001b[K[\u001b[1;34mdefault\u001b[m] synchronized from https://opam.ocaml.org\n",
            "\u001b[1;34m[NOTE]\u001b[m The repository 'default' will be *\u001b[01mpermanently\u001b[m* redirected to\n",
            "       https://opam.ocaml.org/1.2.2 (opam-version < \"2.0~\")\n",
            "\u001b[K[\u001b[1;34mdefault\u001b[m] synchronized from https://opam.ocaml.org/1.2.2\n",
            "\n",
            "\u001b[36m=-=-\u001b[m \u001b[01mGathering sources\u001b[m \u001b[36m=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=\u001b[m\n",
            "\n",
            "\u001b[36m=-=-\u001b[m \u001b[01mProcessing actions\u001b[m \u001b[36m-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=\u001b[m\n",
            "\u001b[32m∗ \u001b[m installed \u001b[01mbase-bigarray\u001b[m.base\n",
            "\u001b[32m∗ \u001b[m installed \u001b[01mbase-threads\u001b[m.base\n",
            "\u001b[32m∗ \u001b[m installed \u001b[01mbase-unix\u001b[m.base\n",
            "Done.\n",
            "\n",
            "In normal operation, OPAM only alters files within ~/.opam.\n",
            "\n",
            "During this initialisation, you can allow OPAM to add information to two\n",
            "other files for best results. You can also make these additions manually\n",
            "if you wish.\n",
            "\n",
            "If you agree, OPAM will modify:\n",
            "\n",
            "  - \u001b[36m~/.profile\u001b[m (or a file you specify) to set the right environment\n",
            "    variables and to load the auto-completion scripts for your shell (\u001b[01mbash\u001b[m)\n",
            "    on startup. Specifically, it checks for and appends the following line:\n",
            "\n",
            "    . /root/.opam/opam-init/init.sh > /dev/null 2> /dev/null || true\n",
            "\n",
            "\n",
            "  - \u001b[36m~/.ocamlinit\u001b[m to ensure that non-system installations of `ocamlfind`\n",
            "    (i.e. those installed by OPAM) will work correctly when running the\n",
            "    OCaml toplevel. It does this by adding $OCAML_TOPLEVEL_PATH to the list\n",
            "    of include directories.\n",
            "\n",
            "If you choose to not configure your system now, you can either configure\n",
            "OPAM manually (instructions will be displayed) or launch the automatic setup\n",
            "later by running:\n",
            "\n",
            "   opam config setup -a\n",
            "\n",
            "\n",
            "Do you want OPAM to modify ~/.profile and ~/.ocamlinit?\n",
            "(default is 'no', use 'f' to name a file other than ~/.profile)\n",
            "    [N/y/f] \n",
            "\n",
            "Global configuration:\n",
            "  Updating ~/.opam/opam-init/init.sh\n",
            "  Updating ~/.opam/opam-init/init.zsh\n",
            "  Updating ~/.opam/opam-init/init.csh\n",
            "  Updating ~/.opam/opam-init/init.fish\n",
            "\n",
            "\u001b[36m=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=\u001b[m\n",
            "\n",
            "\u001b[33m1.\u001b[m To configure OPAM in the current shell session, you need to run:\n",
            "\n",
            "      eval `opam config env`\n",
            "\n",
            "\u001b[33m2.\u001b[m To correctly configure OPAM for subsequent use, add the following\n",
            "   line to your profile file (for instance ~/.profile):\n",
            "\n",
            "      . /root/.opam/opam-init/init.sh > /dev/null 2> /dev/null || true\n",
            "\n",
            "\u001b[33m3.\u001b[m To avoid issues related to non-system installations of `ocamlfind`\n",
            "   add the following lines to ~/.ocamlinit (create it if necessary):\n",
            "\n",
            "      let () =\n",
            "        try Topdirs.dir_directory (Sys.getenv \"OCAML_TOPLEVEL_PATH\")\n",
            "        with Not_found -> ()\n",
            "      ;;\n",
            "\n",
            "\u001b[36m=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=\u001b[m\n",
            "\n",
            "\u001b[33m[WARNING]\u001b[m Running as root is not recommended\n",
            "\n",
            "\u001b[36m=-=-\u001b[m \u001b[01mUpdating package repositories\u001b[m \u001b[36m=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=\u001b[m\n",
            "\u001b[K[\u001b[1;34mdefault\u001b[m] synchronized from https://opam.ocaml.org/1.2.2\n",
            "\u001b[33m[WARNING]\u001b[m Running as root is not recommended\n",
            "The following actions will be performed:\n",
            "  \u001b[32m∗ \u001b[m install \u001b[01mdepext\u001b[m 1.0.5\n",
            "\n",
            "\u001b[36m=-=-\u001b[m \u001b[01mGathering sources\u001b[m \u001b[36m=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=\u001b[m\n",
            "\u001b[K[\u001b[1;34mdefault\u001b[m] https://opam.ocaml.org/1.2.2/archives/depext.1.0.5+opam.tar.gz downloaded\n",
            "\n",
            "\u001b[36m=-=-\u001b[m \u001b[01mProcessing actions\u001b[m \u001b[36m-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=\u001b[m\n",
            "\u001b[K\u001b[32m∗ \u001b[m installed \u001b[01mdepext\u001b[m.1.0.5\n",
            "Done.\n",
            "# Detecting depexts using flags: x86_64 linux ubuntu\n",
            "# The following system packages are needed:\n",
            "#  - camlp4-extra\n",
            "#  - debianutils\n",
            "#  - libcurl4-gnutls-dev\n",
            "#  - libfuse-dev\n",
            "#  - libgmp-dev\n",
            "#  - libsqlite3-dev\n",
            "#  - m4\n",
            "#  - perl\n",
            "#  - pkg-config\n",
            "#  - zlib1g-dev\n",
            "# The following new OS packages need to be installed: libcurl4-gnutls-dev libfuse-dev libgmp-dev libsqlite3-dev m4\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "The following package was automatically installed and is no longer required:\n",
            "  libnvidia-common-410\n",
            "Use 'apt autoremove' to remove it.\n",
            "The following additional packages will be installed:\n",
            "  libgmpxx4ldbl libselinux1-dev libsepol1-dev libsigsegv2\n",
            "Suggested packages:\n",
            "  libcurl4-doc libgnutls28-dev libidn11-dev libkrb5-dev libldap2-dev\n",
            "  librtmp-dev libssh2-1-dev gmp-doc libgmp10-doc libmpfr-dev sqlite3-doc\n",
            "  m4-doc\n",
            "The following packages will be REMOVED:\n",
            "  libcurl4-openssl-dev\n",
            "The following NEW packages will be installed:\n",
            "  libcurl4-gnutls-dev libfuse-dev libgmp-dev libgmpxx4ldbl libselinux1-dev\n",
            "  libsepol1-dev libsigsegv2 libsqlite3-dev m4\n",
            "0 upgraded, 9 newly installed, 1 to remove and 4 not upgraded.\n",
            "Need to get 2,042 kB of archives.\n",
            "After this operation, 7,336 kB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 libcurl4-gnutls-dev amd64 7.58.0-2ubuntu3.7 [294 kB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu bionic/main amd64 libsepol1-dev amd64 2.7-1 [324 kB]\n",
            "Get:3 http://archive.ubuntu.com/ubuntu bionic/main amd64 libselinux1-dev amd64 2.7-2build2 [149 kB]\n",
            "Get:4 http://archive.ubuntu.com/ubuntu bionic/main amd64 libfuse-dev amd64 2.9.7-1ubuntu1 [105 kB]\n",
            "Get:5 http://archive.ubuntu.com/ubuntu bionic/main amd64 libgmpxx4ldbl amd64 2:6.1.2+dfsg-2 [8,964 B]\n",
            "Get:6 http://archive.ubuntu.com/ubuntu bionic/main amd64 libgmp-dev amd64 2:6.1.2+dfsg-2 [316 kB]\n",
            "Get:7 http://archive.ubuntu.com/ubuntu bionic/main amd64 libsigsegv2 amd64 2.12-1 [14.7 kB]\n",
            "Get:8 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 libsqlite3-dev amd64 3.22.0-1ubuntu0.1 [633 kB]\n",
            "Get:9 http://archive.ubuntu.com/ubuntu bionic/main amd64 m4 amd64 1.4.18-1 [197 kB]\n",
            "Fetched 2,042 kB in 1s (2,139 kB/s)\n",
            "(Reading database ... 134699 files and directories currently installed.)\n",
            "Removing libcurl4-openssl-dev:amd64 (7.58.0-2ubuntu3.7) ...\n",
            "Selecting previously unselected package libcurl4-gnutls-dev:amd64.\n",
            "(Reading database ... 134679 files and directories currently installed.)\n",
            "Preparing to unpack .../0-libcurl4-gnutls-dev_7.58.0-2ubuntu3.7_amd64.deb ...\n",
            "Unpacking libcurl4-gnutls-dev:amd64 (7.58.0-2ubuntu3.7) ...\n",
            "Selecting previously unselected package libsepol1-dev:amd64.\n",
            "Preparing to unpack .../1-libsepol1-dev_2.7-1_amd64.deb ...\n",
            "Unpacking libsepol1-dev:amd64 (2.7-1) ...\n",
            "Selecting previously unselected package libselinux1-dev:amd64.\n",
            "Preparing to unpack .../2-libselinux1-dev_2.7-2build2_amd64.deb ...\n",
            "Unpacking libselinux1-dev:amd64 (2.7-2build2) ...\n",
            "Selecting previously unselected package libfuse-dev.\n",
            "Preparing to unpack .../3-libfuse-dev_2.9.7-1ubuntu1_amd64.deb ...\n",
            "Unpacking libfuse-dev (2.9.7-1ubuntu1) ...\n",
            "Selecting previously unselected package libgmpxx4ldbl:amd64.\n",
            "Preparing to unpack .../4-libgmpxx4ldbl_2%3a6.1.2+dfsg-2_amd64.deb ...\n",
            "Unpacking libgmpxx4ldbl:amd64 (2:6.1.2+dfsg-2) ...\n",
            "Selecting previously unselected package libgmp-dev:amd64.\n",
            "Preparing to unpack .../5-libgmp-dev_2%3a6.1.2+dfsg-2_amd64.deb ...\n",
            "Unpacking libgmp-dev:amd64 (2:6.1.2+dfsg-2) ...\n",
            "Selecting previously unselected package libsigsegv2:amd64.\n",
            "Preparing to unpack .../6-libsigsegv2_2.12-1_amd64.deb ...\n",
            "Unpacking libsigsegv2:amd64 (2.12-1) ...\n",
            "Selecting previously unselected package libsqlite3-dev:amd64.\n",
            "Preparing to unpack .../7-libsqlite3-dev_3.22.0-1ubuntu0.1_amd64.deb ...\n",
            "Unpacking libsqlite3-dev:amd64 (3.22.0-1ubuntu0.1) ...\n",
            "Selecting previously unselected package m4.\n",
            "Preparing to unpack .../8-m4_1.4.18-1_amd64.deb ...\n",
            "Unpacking m4 (1.4.18-1) ...\n",
            "Setting up libsepol1-dev:amd64 (2.7-1) ...\n",
            "Setting up libsqlite3-dev:amd64 (3.22.0-1ubuntu0.1) ...\n",
            "Setting up libsigsegv2:amd64 (2.12-1) ...\n",
            "Setting up m4 (1.4.18-1) ...\n",
            "Processing triggers for libc-bin (2.27-3ubuntu1) ...\n",
            "Processing triggers for man-db (2.8.3-2ubuntu0.1) ...\n",
            "Setting up libgmpxx4ldbl:amd64 (2:6.1.2+dfsg-2) ...\n",
            "Setting up libselinux1-dev:amd64 (2.7-2build2) ...\n",
            "Setting up libcurl4-gnutls-dev:amd64 (7.58.0-2ubuntu3.7) ...\n",
            "Setting up libgmp-dev:amd64 (2:6.1.2+dfsg-2) ...\n",
            "Setting up libfuse-dev (2.9.7-1ubuntu1) ...\n",
            "Processing triggers for libc-bin (2.27-3ubuntu1) ...\n",
            "# OS packages installation successful\n",
            "\u001b[33m[WARNING]\u001b[m Running as root is not recommended\n",
            "The following actions will be performed:\n",
            "  \u001b[32m∗ \u001b[m install \u001b[01mconf-perl\u001b[m              1           [required by zarith]\n",
            "  \u001b[32m∗ \u001b[m install \u001b[01mconf-m4\u001b[m                1           [required by ocamlfind]\n",
            "  \u001b[32m∗ \u001b[m install \u001b[01mconf-gmp\u001b[m               1           [required by conf-gmp-powm-sec, zarith]\n",
            "  \u001b[32m∗ \u001b[m install \u001b[01mconf-pkg-config\u001b[m        1.1         [required by conf-zlib, conf-sqlite3]\n",
            "  \u001b[32m∗ \u001b[m install \u001b[01mconf-libcurl\u001b[m           1           [required by ocurl]\n",
            "  \u001b[32m∗ \u001b[m install \u001b[01mdune\u001b[m                   1.2.1       [required by jbuilder]\n",
            "  \u001b[32m∗ \u001b[m install \u001b[01mcamlidl\u001b[m                1.05        [required by google-drive-ocamlfuse]\n",
            "  \u001b[32m∗ \u001b[m install \u001b[01mconf-which\u001b[m             1           [required by biniou]\n",
            "  \u001b[32m∗ \u001b[m install \u001b[01mocamlbuild\u001b[m             0.12.0      [required by cryptokit]\n",
            "  \u001b[32m∗ \u001b[m install \u001b[01mocamlfind\u001b[m              1.8.0       [required by extlib, cryptokit, ocamlfuse]\n",
            "  \u001b[32m∗ \u001b[m install \u001b[01mconf-gmp-powm-sec\u001b[m      1           [required by cryptokit]\n",
            "  \u001b[32m∗ \u001b[m install \u001b[01mconf-zlib\u001b[m              1           [required by cryptokit]\n",
            "  \u001b[32m∗ \u001b[m install \u001b[01mconf-sqlite3\u001b[m           1           [required by sqlite3]\n",
            "  \u001b[32m∗ \u001b[m install \u001b[01mjbuilder\u001b[m               transition  [required by google-drive-ocamlfuse]\n",
            "  \u001b[32m∗ \u001b[m install \u001b[01mzarith\u001b[m                 1.7         [required by cryptokit]\n",
            "  \u001b[32m∗ \u001b[m install \u001b[01mocurl\u001b[m                  0.8.2       [required by gapi-ocaml]\n",
            "  \u001b[32m∗ \u001b[m install \u001b[01mocamlfuse\u001b[m              2.7.1-cvs5  [required by google-drive-ocamlfuse]\n",
            "  \u001b[32m∗ \u001b[m install \u001b[01mbase-bytes\u001b[m             base        [required by extlib]\n",
            "  \u001b[32m∗ \u001b[m install \u001b[01msexplib0\u001b[m               v0.11.0     [required by base]\n",
            "  \u001b[32m∗ \u001b[m install \u001b[01mresult\u001b[m                 1.3         [required by topkg]\n",
            "  \u001b[32m∗ \u001b[m install \u001b[01measy-format\u001b[m            1.3.1       [required by yojson]\n",
            "  \u001b[32m∗ \u001b[m install \u001b[01mcppo\u001b[m                   1.6.5       [required by extlib]\n",
            "  \u001b[32m∗ \u001b[m install \u001b[01mcryptokit\u001b[m              1.13        [required by google-drive-ocamlfuse]\n",
            "  \u001b[32m∗ \u001b[m install \u001b[01mocamlnet\u001b[m               4.1.6       [required by gapi-ocaml]\n",
            "  \u001b[32m∗ \u001b[m install \u001b[01mbase\u001b[m                   v0.11.1     [required by sqlite3]\n",
            "  \u001b[32m∗ \u001b[m install \u001b[01mtopkg\u001b[m                  0.9.1       [required by xmlm]\n",
            "  \u001b[32m∗ \u001b[m install \u001b[01mbiniou\u001b[m                 1.2.0       [required by yojson]\n",
            "  \u001b[32m∗ \u001b[m install \u001b[01mextlib\u001b[m                 1.7.5       [required by google-drive-ocamlfuse]\n",
            "  \u001b[32m∗ \u001b[m install \u001b[01mstdio\u001b[m                  v0.11.0     [required by sqlite3]\n",
            "  \u001b[32m∗ \u001b[m install \u001b[01mxmlm\u001b[m                   1.3.0       [required by gapi-ocaml]\n",
            "  \u001b[32m∗ \u001b[m install \u001b[01myojson\u001b[m                 1.4.1       [required by gapi-ocaml]\n",
            "  \u001b[32m∗ \u001b[m install \u001b[01mconfigurator\u001b[m           v0.11.0     [required by sqlite3]\n",
            "  \u001b[32m∗ \u001b[m install \u001b[01mgapi-ocaml\u001b[m             0.3.6       [required by google-drive-ocamlfuse]\n",
            "  \u001b[32m∗ \u001b[m install \u001b[01msqlite3\u001b[m                4.4.0       [required by google-drive-ocamlfuse]\n",
            "  \u001b[32m∗ \u001b[m install \u001b[01mgoogle-drive-ocamlfuse\u001b[m 0.6.23    \n",
            "===== \u001b[32m∗ \u001b[m 35 =====\n",
            "Do you want to continue ? [Y/n] Y\n",
            "\n",
            "\u001b[36m=-=-\u001b[m \u001b[01mGathering sources\u001b[m \u001b[36m=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=\u001b[m\n",
            "\u001b[K[\u001b[1;34mdefault\u001b[m] https://opam.ocaml.org/1.2.2/archives/biniou.1.2.0+opam.tar.gz downloaded\n",
            "\u001b[K[\u001b[1;34mdefault\u001b[m] https://opam.ocaml.org/1.2.2/archives/camlidl.1.05+opam.tar.gz downloaded\n",
            "\u001b[K[\u001b[1;34mdefault\u001b[m] https://opam.ocaml.org/1.2.2/archives/configurator.v0.11.0+opam.tar.gz downloaded\n",
            "\u001b[K[\u001b[1;34mdefault\u001b[m] https://opam.ocaml.org/1.2.2/archives/base.v0.11.1+opam.tar.gz downloaded\n",
            "\u001b[K[\u001b[1;34mdefault\u001b[m] https://opam.ocaml.org/1.2.2/archives/cppo.1.6.5+opam.tar.gz downloaded\n",
            "\u001b[K[\u001b[1;34mdefault\u001b[m] https://opam.ocaml.org/1.2.2/archives/easy-format.1.3.1+opam.tar.gz downloaded\n",
            "\u001b[K[\u001b[1;34mdefault\u001b[m] https://opam.ocaml.org/1.2.2/archives/cryptokit.1.13+opam.tar.gz downloaded\n",
            "\u001b[K[\u001b[1;34mdefault\u001b[m] https://opam.ocaml.org/1.2.2/archives/dune.1.2.1+opam.tar.gz downloaded\n",
            "\u001b[K[\u001b[1;34mdefault\u001b[m] https://opam.ocaml.org/1.2.2/archives/extlib.1.7.5+opam.tar.gz downloaded\n",
            "\u001b[K[\u001b[1;34mdefault\u001b[m] https://opam.ocaml.org/1.2.2/archives/google-drive-ocamlfuse.0.6.23+opam.tar.gz downloaded\n",
            "\u001b[K[\u001b[1;34mdefault\u001b[m] https://opam.ocaml.org/1.2.2/archives/gapi-ocaml.0.3.6+opam.tar.gz downloaded\n",
            "\u001b[K[\u001b[1;34mdefault\u001b[m] https://opam.ocaml.org/1.2.2/archives/ocamlbuild.0.12.0+opam.tar.gz downloaded\n",
            "\u001b[K[\u001b[1;34mdefault\u001b[m] https://opam.ocaml.org/1.2.2/archives/ocamlfind.1.8.0+opam.tar.gz downloaded\n",
            "\u001b[K[\u001b[1;34mdefault\u001b[m] https://opam.ocaml.org/1.2.2/archives/ocamlfuse.2.7.1-cvs5+opam.tar.gz downloaded\n",
            "\u001b[K[\u001b[1;34mdefault\u001b[m] https://opam.ocaml.org/1.2.2/archives/result.1.3+opam.tar.gz downloaded\n",
            "\u001b[K[\u001b[1;34mdefault\u001b[m] https://opam.ocaml.org/1.2.2/archives/ocurl.0.8.2+opam.tar.gz downloaded\n",
            "\u001b[K[\u001b[1;34mdefault\u001b[m] https://opam.ocaml.org/1.2.2/archives/sexplib0.v0.11.0+opam.tar.gz downloaded\n",
            "\u001b[K[\u001b[1;34mdefault\u001b[m] https://opam.ocaml.org/1.2.2/archives/sqlite3.4.4.0+opam.tar.gz downloaded\n",
            "\u001b[K[\u001b[1;34mdefault\u001b[m] https://opam.ocaml.org/1.2.2/archives/stdio.v0.11.0+opam.tar.gz downloaded\n",
            "\u001b[K[\u001b[1;34mdefault\u001b[m] https://opam.ocaml.org/1.2.2/archives/topkg.0.9.1+opam.tar.gz downloaded\n",
            "\u001b[K[\u001b[1;34mdefault\u001b[m] https://opam.ocaml.org/1.2.2/archives/xmlm.1.3.0+opam.tar.gz downloaded\n",
            "\u001b[K[\u001b[1;34mdefault\u001b[m] https://opam.ocaml.org/1.2.2/archives/ocamlnet.4.1.6+opam.tar.gz downloaded\n",
            "\u001b[K[\u001b[1;34mdefault\u001b[m] https://opam.ocaml.org/1.2.2/archives/yojson.1.4.1+opam.tar.gz downloaded\n",
            "\u001b[K[\u001b[1;34mdefault\u001b[m] https://opam.ocaml.org/1.2.2/archives/zarith.1.7+opam.tar.gz downloaded\n",
            "\n",
            "\u001b[36m=-=-\u001b[m \u001b[01mProcessing actions\u001b[m \u001b[36m-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=\u001b[m\n",
            "\u001b[K\u001b[32m∗ \u001b[m installed \u001b[01mconf-m4\u001b[m.1\n",
            "\u001b[K\u001b[32m∗ \u001b[m installed \u001b[01mconf-perl\u001b[m.1\n",
            "\u001b[K\u001b[32m∗ \u001b[m installed \u001b[01mconf-libcurl\u001b[m.1\n",
            "\u001b[K\u001b[32m∗ \u001b[m installed \u001b[01mconf-pkg-config\u001b[m.1.1\n",
            "\u001b[K\u001b[32m∗ \u001b[m installed \u001b[01mconf-which\u001b[m.1\n",
            "\u001b[K\u001b[32m∗ \u001b[m installed \u001b[01mconf-sqlite3\u001b[m.1\n",
            "\u001b[K\u001b[32m∗ \u001b[m installed \u001b[01mconf-zlib\u001b[m.1\n",
            "\u001b[K\u001b[32m∗ \u001b[m installed \u001b[01mconf-gmp\u001b[m.1\n",
            "\u001b[K\u001b[32m∗ \u001b[m installed \u001b[01mconf-gmp-powm-sec\u001b[m.1\n",
            "\u001b[K\u001b[32m∗ \u001b[m installed \u001b[01mcamlidl\u001b[m.1.05\n",
            "\u001b[K\u001b[32m∗ \u001b[m installed \u001b[01mocamlfind\u001b[m.1.8.0\n",
            "\u001b[K\u001b[32m∗ \u001b[m installed \u001b[01mbase-bytes\u001b[m.base\n",
            "\u001b[K\u001b[32m∗ \u001b[m installed \u001b[01mocamlbuild\u001b[m.0.12.0\n",
            "\u001b[K\u001b[32m∗ \u001b[m installed \u001b[01mocamlfuse\u001b[m.2.7.1-cvs5\n",
            "\u001b[K\u001b[32m∗ \u001b[m installed \u001b[01mzarith\u001b[m.1.7\n",
            "\u001b[K\u001b[32m∗ \u001b[m installed \u001b[01mdune\u001b[m.1.2.1\n",
            "\u001b[K\u001b[32m∗ \u001b[m installed \u001b[01mjbuilder\u001b[m.transition\n",
            "\u001b[K\u001b[32m∗ \u001b[m installed \u001b[01mcppo\u001b[m.1.6.5\n",
            "\u001b[K\u001b[32m∗ \u001b[m installed \u001b[01measy-format\u001b[m.1.3.1\n",
            "\u001b[K\u001b[32m∗ \u001b[m installed \u001b[01mbiniou\u001b[m.1.2.0\n",
            "\u001b[K\u001b[32m∗ \u001b[m installed \u001b[01mcryptokit\u001b[m.1.13\n",
            "\u001b[K\u001b[32m∗ \u001b[m installed \u001b[01mresult\u001b[m.1.3\n",
            "\u001b[K\u001b[32m∗ \u001b[m installed \u001b[01mextlib\u001b[m.1.7.5\n",
            "\u001b[K\u001b[32m∗ \u001b[m installed \u001b[01msexplib0\u001b[m.v0.11.0\n",
            "\u001b[K\u001b[32m∗ \u001b[m installed \u001b[01mtopkg\u001b[m.0.9.1\n",
            "\u001b[K\u001b[32m∗ \u001b[m installed \u001b[01mxmlm\u001b[m.1.3.0\n",
            "\u001b[K\u001b[32m∗ \u001b[m installed \u001b[01myojson\u001b[m.1.4.1\n",
            "\u001b[K\u001b[32m∗ \u001b[m installed \u001b[01mbase\u001b[m.v0.11.1\n",
            "\u001b[K\u001b[32m∗ \u001b[m installed \u001b[01mstdio\u001b[m.v0.11.0\n",
            "\u001b[K\u001b[32m∗ \u001b[m installed \u001b[01mconfigurator\u001b[m.v0.11.0\n",
            "\u001b[K\u001b[32m∗ \u001b[m installed \u001b[01mocurl\u001b[m.0.8.2\n",
            "\u001b[K\u001b[32m∗ \u001b[m installed \u001b[01msqlite3\u001b[m.4.4.0\n",
            "\u001b[K\u001b[32m∗ \u001b[m installed \u001b[01mocamlnet\u001b[m.4.1.6\n",
            "\u001b[K\u001b[32m∗ \u001b[m installed \u001b[01mgapi-ocaml\u001b[m.0.3.6\n",
            "\u001b[K\u001b[32m∗ \u001b[m installed \u001b[01mgoogle-drive-ocamlfuse\u001b[m.0.6.23\n",
            "Done.\n",
            "\n",
            "\u001b[36m=-=-\u001b[m \u001b[01mjbuilder.transition installed successfully\u001b[m \u001b[36m-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=\u001b[m\n",
            "\u001b[32m=> \u001b[mJbuilder has been renamed and the jbuilder package is now a transition\n",
            "   package. Use the dune package instead.\n",
            "Please, open the following URL in a web browser: https://accounts.google.com/o/oauth2/auth?client_id=32555940559.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive&response_type=code&access_type=offline&approval_prompt=force\n",
            "··········\n",
            "Please, open the following URL in a web browser: https://accounts.google.com/o/oauth2/auth?client_id=32555940559.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive&response_type=code&access_type=offline&approval_prompt=force\n",
            "Please enter the verification code: Access token retrieved correctly.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pjPqGd7p0BR_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!cat /content/drive/T-news_sohusite_xml.txt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o9g_zKFK0EfK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}